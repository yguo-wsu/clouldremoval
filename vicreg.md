2个数据集： imdb和yelp 2分类
训练集随机抽取80条，测试集随机抽取60条==》50次
1. 修改参数 λ=>mse=>25;µ=>variance=>25;ν=>co-var=>1
2. 原始模型；；；；；； 原始+增强模型；；；；；；原始+增强+3个loss（训练和测试样本是一样的， 增强的样本也是一样的）





# 纯增强（Ohsumed Baseline：0.7151）

max_length = 128;epochs=60; learning_rate=1e-5;batch_size=64



## 0 Character Augmenter

- Keyboard Augmenter--**Substitute** character by keyboard distance √

  实验结果：0.7198

  ```
  Original:
  The quick brown fox jumps over the lazy dog .
  Augmented Text:
  The quick brown Gox juJps ocer the lazy dog .
  ```

- Random Augmenter--**Insert** character randomly

  实验结果：0.7153

  ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  T3he quicNk @brown fEox juamps $over th6e la1zy d*og
  ```

- Random Augmenter--**Swap** character randomly  √

  实验结果：0.7279

  实验结果（shuffle）：0.7203

  ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  Hte quikc borwn fxo jupms ovre teh lzay dgo
  ```

- Random Augmenter--**Delete** character randomly

  实验结果：0.7094

  ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  Te quic rown fx jump ver he laz og
  ```

## 1 Word Augmenter

- Spelling Augmenter--Substitute word by spelling mistake words dictionary  

  实验结果：0.7264

  ```
  Original:
  The quick brown fox jumps over the lazy dog .
  Augmented Texts:
  ['Tha qchick brown fox jumps ower the lazy dog.', 'Their quick borwn fox jumps over tge lazy dog.', 'The qchick brown fox jumps ower the lazy dod.']
  ```

- Random Word Augmenter--Swap word randomly

  实验结果：0.7106

  实验结果（shuffle）：0.7198

  ```
  Original:
  The quick brown fox jumps over the lazy dog .
  Augmented Text:
  Quick the brown fox jumps over the lazy dog .
  ```

- Random Word Augmenter--Delete word randomly √

  实验结果：（改名）0.7178

  ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  The brown jumps over the lazy dog
  ```

- Contextual Word Embeddings Augmenter--Insert word by contextual word embeddings（roberta-base） √

  实验结果：0.7279

  ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  even the quick brown fox usually jumps over the lazy dog
  ```

- Contextual Word Embeddings Augmenter--Substitute word by contextual word embeddings（roberta-base）

  实验结果：0.7126

- ```
  Original:
  The quick brown fox jumps over the lazy dog
  Augmented Text:
  little quick brown fox jumps over the lazy dog
  ```


- Random Word Augmenter -- Delete a set of contunous word will be removed randomly

  实验结果：0.7173

  ```
  Original:
  The quick brown fox jumps over the lazy dog .
  Augmented Text:
  The quick brown fox jumps dog .
  ```

# 方法统计

（1）字符级别：Substitute character && Swap character randomly character randomly

- aug = nac.KeyboardAug()
- aug = nac.RandomCharAug(action="swap")

（2）单词级别：Delete word randomly &&  Insert word			

- aug = naw.RandomWordAug()
- aug = naw.ContextualWordEmbsAug(model_path='roberta-base', action="insert")

  (3)句子级别：Abstractive Summarization Augmenter（缩句）

- aug = nas.AbstSummAug(model_path='t5-base')

  



# 实验

## 纯增强

| 方法                      | 结果   | △    |
| ------------------------- | ------ | ---- |
| Substitute character      | 0.7198 | 0.4  |
| Swap character            | 0.7279 | 1.2  |
| Delete word               | 0.7178 | 0.2  |
| Insert word               | 0.7279 | 1.3  |
| Abstractive Summarization | 0.7305 | 1.5  |
|                           |        |      |

## 混合增强

| 方法                                                       | 结果   | △    |
| ---------------------------------------------------------- | ------ | ---- |
| 两重增强                                                   |        |      |
| Substitute character+Swap character                        | 0.7143 | ---  |
| Delete word+Substitute character                           | 0.7109 |      |
| Delete word+Swap character                                 | 0.7183 |      |
| Insert word+Substitute character                           | 0.7156 |      |
| Insert word+Swap character                                 | 0.7247 |      |
| Abstractive Summarization+Substitute character             | 0.7069 |      |
| Abstractive Summarization+Swap character                   | 0.7007 |      |
| Abstractive Summarization+Insert word                      | 0.7215 |      |
| Abstractive Summarization+Delete word                      | 0.7114 |      |
| Insert word+Abstractive Summarization                      | 0.7210 |      |
| Delete word+Abstractive Summarization                      | 0.7153 |      |
|                                                            |        |      |
| 三重增强                                                   |        |      |
| Delete word+Abstractive Summarization+Substitute character | 0.7086 |      |
| Delete word+Abstractive Summarization+Swap character       | 0.7086 |      |
| Insert word+Abstractive Summarization+Substitute character | 0.7106 |      |
| Insert word+Abstractive Summarization+Swap character       | 0.7039 |      |
|                                                            |        |      |
| Abstractive Summarization+Delete word+Substitute character | 0.7034 |      |
| Abstractive Summarization+Delete word+Swap character       |        |      |
| Abstractive Summarization+Insert word+Substitute character |        |      |
| Abstractive Summarization+Insert word+Swap character       |        |      |
|                                                            |        |      |
| Substitute character+Abstractive Summarization+Delete word | 0.7071 |      |
| Substitute character+Abstractive Summarization+Insert word | 0.7146 |      |
| Swap character+Abstractive Summarization+Delete word       | 0.7069 |      |
| Swap character+Abstractive Summarization+Insert word       | 0.7064 |      |
|                                                            |        |      |
| Substitute character+Delete word+Abstractive Summarization | 0.7252 |      |
| Swap character+Delete word+Abstractive Summarization       | 0.7200 |      |
| Substitute character+Insert word+Abstractive Summarization | 0.7076 |      |
| Swap character+Insert word+Abstractive Summarization       | 0.7156 |      |



## 混合增强+Loss

| 方法                                          | Loss | 结果   | △    |
| --------------------------------------------- | ---- | ------ | ---- |
| Insert word                                   | 欧式 | 0.7175 | 0.2  |
| Substitute character + Swap character         | 欧式 | 0.7210 | 0.7  |
| Substitute character + Delete word            | 欧式 | 0.7255 | 1.0  |
| Substitute character + Delete word（shuffle） | 欧式 | 0.7250 | 1.0  |
| Substitute character + Insert word            | 欧式 | 0.7222 | 0.7  |
| Swap character + Delete word                  | 欧式 | 0.7185 | 0.3  |
| Swap character + Insert word                  | 欧式 | 0.7121 | -0.3 |



## 指标测试 Ohsumed 23分类（Test Dataset）

- Baseline：0.7151
- Variance: 方差
- Invariance：MSE_loss（求原始样本，增强前后的平均池化向量之间的均方距离）
- （不变性）EI：衡量两个模型输出的一致性
- MI指标

| Aug_Model                     | Aug_acc | △    | Variance_Aug | Variance_Origin | △     | Invariance（23类） | EI     |
| ----------------------------- | ------- | ---- | ------------ | --------------- | ----- | ------------------ | ------ |
| Abs Summ                      | 0.7305  | 1.5  | 0.0877       | 0.0561          | 0.031 | 0.8111             | 0.7625 |
| Insert word+Swap char         | 0.7247  | 0.9  | 0.0806       | 0.0561          | 0.024 | 0.8055             | 0.7750 |
| Abs Summ+Insert word          | 0.7215  | 0.6  | 0.0717       | 0.0561          | 0.015 | 0.7938             | 0.7600 |
| Abs Summ+Substitute character | 0.7069  | -0.9 | 0.0950       | 0.0561          | 0.039 | 0.8235             | 0.7475 |
| Abs Summ+Swap character       | 0.7007  | -1.5 | 0.1100       | 0.0561          | 0.054 | 0.8011             | 0.7429 |



##  指标测试 IMDB 二分类（Test Dataset）

- Baseline Dev Acc = 58%

- 小样本数据增强，训练集80条，验证集60条，其中每一类的条数相同；
- 增强方法：词替换（CW）
- 随机种子：59

| Acc  | △    | Var_Ori_A | Var_Ori_B | Var_Aug_A | Var_Aug_B | EI    | MSE_A | MSE_B | Cos_A | Cos_B |
| ---- | ---- | --------- | --------- | --------- | --------- | ----- | ----- | ----- | ----- | ----- |
| 64   | 6    | 0.452     | 0.436     | 0.328     | 0.269     | 0.700 | 0.251 | 0.290 | 0.400 | 0.370 |
| 67   | 8    | 0.452     | 0.436     | 0.310     | 0.324     | 0.378 | 0.274 | 0.245 | 0.355 | 0.393 |
| 69   | 11   | 0.452     | 0.436     | 0.298     | 0.233     | 0.653 | 0.280 | 0.311 | 0.341 | 0.311 |
| 71   | 13   | 0.452     | 0.436     | 0.275     | 0.288     | 0.448 | 0.327 | 0.311 | 0.268 | 0.268 |

- 增强方法：回传（Back Translation）
- 随机种子：59

| Acc  | △    | Var_Ori_A | Var_Ori_B | Var_Aug_A | Var_Aug_B | EI    | MSE_A | MSE_B | Cos_A | Cos_B |
| ---- | ---- | --------- | --------- | --------- | --------- | ----- | ----- | ----- | ----- | ----- |
| 63   | 5    | 0.452     | 0.436     | 0.434     | 0.421     | 0.588 | 0.018 | 0.021 | 0.907 | 0.897 |
| 69   | 11   | 0.452     | 0.436     | 0.386     | 0.341     | 0.614 | 0.127 | 0.162 | 0.663 | 0.611 |
| 74   | 16   | 0.452     | 0.436     | 0.433     | 0.422     | 0.425 | 0.038 | 0.042 | 0.848 | 0.843 |
| 82   | 24   | 0.452     | 0.436     | 0.285     | 0.294     | 0.392 | 0.237 | 0.211 | 0.481 | 0.536 |



字符级别：

- 1：nac.OcrAug
- 2：nac.RandomCharAug_delete
- 3：nac.RandomCharAug_sub
- 4：nac.RandomCharAug_swap
- 5：KeyboardAug（nac）

单词级别：

- 6：词替换（Robert）
- 7：crop（连续删除词）
- 8：词替换（Bert-base）
- 9：词插入（Bert-base）
- 10：回传

句子级别

- 11：摘要

**规律**：

（1）增强后，方差更小；（2）EI值不确定；（3）同一种增强方法，增强好的比增强差的，都与base相比，均方距离更大，余弦相似度更小；（4）增强前后A与B之间首先平均池化得到中心点，MSE距离变大；（5）增强最好的模型与base相比，协方差矩阵值更大；但增强较次的模型与base相比，协方差矩阵值会小一点，协方差值可能先降再升

补：KPCA+高斯分布图

| 方法   | Acc  | Var_A | Var_B | Ave   | EI    | MSE_A | MSE_B | Ave   | Cos_A | Cos_B | Ave   |
| ------ | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1      | 75   | 0.277 | 0.278 | 0.278 | 0.401 | 0.241 | 0.207 | 0.224 | 0.427 | 0.492 | 0.460 |
| 2      | 75   | 0.316 | 0.307 | 0.312 | 0.418 | 0.176 | 0.166 | 0.171 | 0.621 | 0.644 | 0.632 |
| **3**  | 66   | 0.425 | 0.410 | 0.418 | 0.261 | 0.018 | 0.018 | 0.018 | 0.910 | 0.914 | 0.912 |
| **3**  | 75   | 0.333 | 0.318 | 0.326 | 0.503 | 0.162 | 0.156 | 0.159 | 0.643 | 0.663 | 0.653 |
| 4      | 77   | 0.278 | 0.243 | 0.261 | 0.563 | 0.225 | 0.239 | 0.232 | 0.533 | 0.524 | 0.528 |
| **5**  | 63   | 0.449 | 0.432 | 0.441 | 0.559 | 0.010 | 0.008 | 0.009 | 0.953 | 0.960 | 0.956 |
| **5**  | 77   | 0.325 | 0.264 | 0.294 | 0.525 | 0.219 | 0.255 | 0.237 | 0.477 | 0.433 | 0.460 |
| 6      | 69   | 0.325 | 0.322 | 0.324 | 0.477 | 0.251 | 0.236 | 0.243 | 0.405 | 0.422 | 0.414 |
| 7      | 74   | 0.189 | 0.196 | 0.192 | 0.492 | 0.344 | 0.327 | 0.336 | 0.317 | 0.347 | 0.332 |
| **8**  | 68   | 0.438 | 0.422 | 0.430 | 0.404 | 0.018 | 0.018 | 0.018 | 0.908 | 0.912 | 0.910 |
| **8**  | 79   | 0.274 | 0.264 | 0.269 | 0.470 | 0.217 | 0.209 | 0.213 | 0.547 | 0.565 | 0.556 |
| **9**  | 69   | 0.337 | 0.280 | 0.308 | 0.647 | 0.181 | 0.218 | 0.200 | 0.558 | 0.506 | 0.532 |
| **9**  | 82   | 0.296 | 0.276 | 0.286 | 0.526 | 0.233 | 0.228 | 0.231 | 0.476 | 0.491 | 0.484 |
| 10     | 82   | 0.285 | 0.294 | 0.290 | 0.392 | 0.237 | 0.211 | 0.224 | 0.481 | 0.536 | 0.509 |
| **11** | 67   | 0.456 | 0.436 | 0.446 | 0.506 | 0.019 | 0.019 | 0.019 | 0.911 | 0.911 | 0.911 |
| **11** | 77   | 0.365 | 0.373 | 0.369 | 0.509 | 0.153 | 0.141 | 0.147 | 0.620 | 0.649 | 0.635 |

-O_MSE:增强前A与B之间向量平均池化后得到中心点，再算MSE距离

-O_C_A：Base模型A类的协方差矩阵值

| 方法 | Acc  | O_MSE | A_MSE | O_C_A | O_C_B | Ave   | A_C_A | A_C_B | Ave   |
| ---- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 3    | 66   | 0.004 | 0.001 | 0.304 | 0.293 | 0.298 | 0.256 | 0.244 | 0.250 |
| 3    | 75   | 0.004 | 0.119 | 0.304 | 0.293 | 0.298 | 0.387 | 0.386 | 0.387 |
| 5    | 63   | 0.004 | 0.003 | 0.304 | 0.293 | 0.298 | 0.296 | 0.282 | 0.289 |
| 5    | 77   | 0.004 | 0.209 | 0.304 | 0.293 | 0.298 | 0.380 | 0.376 | 0.378 |
| 8    | 68   | 0.004 | 0.002 | 0.304 | 0.293 | 0.298 | 0.279 | 0.265 | 0.272 |
| 8    | 79   | 0.004 | 0.127 | 0.304 | 0.293 | 0.298 | 0.382 | 0.375 | 0.379 |
| 9    | 69   | 0.004 | 0.123 | 0.304 | 0.293 | 0.298 | 0.371 | 0.366 | 0.369 |
| 9    | 82   | 0.004 | 0.206 | 0.304 | 0.293 | 0.298 | 0.382 | 0.371 | 0.376 |
| 11   | 67   | 0.004 | 0.004 | 0.304 | 0.293 | 0.298 | 0.308 | 0.289 | 0.298 |
| 11   | 77   | 0.004 | 0.065 | 0.304 | 0.293 | 0.298 | 0.377 | 0.380 | 0.379 |

- VICReg Loss对比

| 方法       | Acc  | Var_A | Var_B | Ave   | EI    | MSE_A | MSE_B | Ave   | Cos_A | Cos_B | Ave   |
| ---------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| BT（摘要） | 77   | 0.365 | 0.373 | 0.369 | 0.509 | 0.153 | 0.141 | 0.147 | 0.620 | 0.649 | 0.635 |
| BT+3Loss   | 74   | 0.550 | 0.534 | 0.542 | 0.457 | 0.061 | 0.062 | 0.062 | 0.649 | 0.651 | 0.650 |

| 方法       | Acc  | O_MSE | A_MSE | O_C_A | O_C_B | Ave   | A_C_A | A_C_B | Ave   |
| ---------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| BT（摘要） | 77   | 0.004 | 0.065 | 0.304 | 0.293 | 0.298 | 0.377 | 0.380 | 0.379 |
| BT+3Loss   | 74   | 0.004 | 0.004 | 0.304 | 0.293 | 0.298 | 0.326 | 0.313 | 0.320 |

## 指标测试 YELP 二分类（Dev Dataset）

- **Baseline** **Dev Acc = 70%**
- 小样本数据增强，训练集80条，验证集60条，其中每一类的条数相同；
- 随机种子：159
- Base模型方差：**Base_Var_A：0.408；Base_Var_B：0.410；Mean：0.409**

方法：

字符级别：

- 1：nac.OcrAug 
- 2：nac.RandomCharAug_delete 
- 4：nac.RandomCharAug_swap 
- 5：KeyboardAug（nac） 

单词级别：

- 7：crop（连续删除词）

- 9：词插入（Bert-base） 

| 方法 | Acc  | Var_A | Var_B | Ave   | EI    | MSE_A | MSE_B | Ave   | Cos_A | Cos_B | Ave   |
| ---- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 5    | 78   | 0.260 | 0.234 | 0.247 | 0.586 | 0.222 | 0.223 | 0.222 | 0.552 | 0.569 | 0.561 |
| 1    | 81   | 0.289 | 0.279 | 0.284 | 0.524 | 0.165 | 0.169 | 0.167 | 0.671 | 0.665 | 0.668 |
| 2    | 78   | 0.311 | 0.298 | 0.304 | 0.539 | 0.128 | 0.130 | 0.129 | 0.740 | 0.744 | 0.742 |
| 9    | 75   | 0.286 | 0.265 | 0.275 | 0.575 | 0.171 | 0.178 | 0.175 | 0.658 | 0.653 | 0.655 |
| 7    | 81   | 0.281 | 0.241 | 0.261 | 0.652 | 0.197 | 0.213 | 0.205 | 0.599 | 0.587 | 0.593 |
| 4    | 75   | 0.252 | 0.242 | 0.247 | 0.489 | 0.232 | 0.224 | 0.228 | 0.531 | 0.564 | 0.548 |

| 方法 | Acc  | O_MSE | A_MSE | O_C_A | O_C_B | Ave   | A_C_A | A_C_B | Ave   |
| ---- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 5    | 78   | 0.019 | 0.149 | 0.291 | 0.303 | 0.297 | 0.381 | 0.385 | 0.383 |
| 1    | 81   | 0.019 | 0.123 | 0.291 | 0.303 | 0.297 | 0.383 | 0.384 | 0.383 |
| 2    | 78   | 0.019 | 0.103 | 0.291 | 0.303 | 0.297 | 0.374 | 0.380 | 0.377 |
| 9    | 75   | 0.019 | 0.123 | 0.291 | 0.303 | 0.297 | 0.381 | 0.384 | 0.382 |
| 7    | 81   | 0.019 | 0.147 | 0.291 | 0.303 | 0.297 | 0.383 | 0.386 | 0.384 |
| 4    | 75   | 0.019 | 0.152 | 0.291 | 0.303 | 0.297 | 0.380 | 0.387 | 0.384 |

- VICReg Loss对比

| 方法    | Acc  | Var_A | Var_B | Ave   | EI    | MSE_A | MSE_B | Ave   | Cos_A | Cos_B | Ave   |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1       | 81   | 0.289 | 0.279 | 0.284 | 0.524 | 0.165 | 0.169 | 0.167 | 0.671 | 0.665 | 0.668 |
| 1+3Loss | 70   | 0.539 | 0.543 | 0.541 | 0.565 | 0.068 | 0.069 | 0.069 | 0.700 | 0.721 | 0.711 |
| 7       | 81   | 0.281 | 0.241 | 0.261 | 0.652 | 0.197 | 0.213 | 0.205 | 0.599 | 0.587 | 0.593 |
| 7+3Loss | 71   | 0.539 | 0.547 | 0.543 | 0.557 | 0.073 | 0.077 | 0.075 | 0.661 | 0.668 | 0.664 |

| 方法    | Acc  | O_MSE | A_MSE | O_C_A | O_C_B | Ave   | A_C_A | A_C_B | Ave   |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1       | 81   | 0.019 | 0.123 | 0.291 | 0.303 | 0.297 | 0.383 | 0.384 | 0.383 |
| 1+3Loss | 70   | 0.019 | 0.007 | 0.291 | 0.303 | 0.297 | 0.319 | 0.328 | 0.324 |
| 7       | 81   | 0.019 | 0.147 | 0.291 | 0.303 | 0.297 | 0.383 | 0.386 | 0.384 |
| 7+3Loss | 71   | 0.019 | 0.008 | 0.291 | 0.303 | 0.297 | 0.322 | 0.335 | 0.328 |

​	首先提出一些性能指标，发现有作用的数据增强在这些性能指标上面会呈现一些规律，于是提出新的数据增强方案，这个方法能够符合规律，再把这个模型放到新的数据集上，效果都比别人好。

## 解释实验过程

### 1 Loss前面参数

​	由于总Loss = L1 + L2 + L3 + L4，其中L1是分类损失，而L2,L3,L4分别是MSE，Variance（方差）和Covariance（协方差）损失，所以L2,L3,L4损失训练时需要添加参数

### 2 Loss设计

​	通过代码讲解

  VIC论文代码在该网页的184行开始：https://github.com/caesar-jojo/jojo/blob/main/%E4%BB%A3%E7%A0%81/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E4%BB%A3%E7%A0%81/%E5%88%AB%E4%BA%BA%E7%9A%84%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81/vicreg-main/main_vicreg.py

```python
def get_Variance(outputs): #计算方差

  Variance = torch.sqrt(torch.mean(torch.var(outputs[:,1:,:],dim=1),dim=1))

  return Variance

def cov_value(x): #计算协方差
    cov = torch.cov(x)
    diag = torch.diag(cov)
    cov_diag = torch.diag_embed(diag)
    new_cov = diag - cov_diag
    return torch.mean(new_cov)

```

```python
 	outputs = self.bert(
                input_ids,
                attention_mask=attention_mask,
                token_type_ids=token_type_ids,
            )

    batch_size = len(input_ids)
    labels = labels.view(labels.size(0))

    output = outputs[0]
    mean_output = torch.mean(outputs[0][:,1:,:],dim=1)
    pooled_output = self.dropout(mean_output)
    logits = self.classifier(pooled_output)
    MSE_distance=torch.nn.MSELoss()

    loss = None
    if labels is not None:
        loss_function = nn.CrossEntropyLoss()
        cls_loss = loss_function(logits,labels)
        if (batch_size % 2) == 0:
            x_Variance = get_Variance(output[ : batch_size // 2])
            y_Variance = get_Variance(output[batch_size // 2 : ])
            x_cov = 0
            y_cov = 0
            for i in range((batch_size // 2)):
                x_cov += cov_value(output[i][ : , 1 : ])
                y_cov += cov_value(output[(batch_size // 2) + i][ : , 1 : ])
                x_cov = x_cov / (batch_size // 2)    
                y_cov = y_cov / (batch_size // 2)    

                MSE_loss = MSE_distance(mean_output[ : batch_size // 2] , mean_output[batch_size // 2 : ])
                Variance_loss = torch.mean(F.relu(1 - x_Variance)) + torch.mean(F.relu(1 - y_Variance))
                Cov_loss = x_cov + y_cov
                loss = MSE_loss + Variance_loss + Cov_loss + cls_loss
```

## 3.得出结论与已有文章的结论不符

​	在《VICReg Variance Invariance-Covariance Regularization for Self-Supervised Learning》中，方差，MSE，协方差计算如下：

- 总Loss

  ![image-20230201230935291](https://user-images.githubusercontent.com/91411874/216242125-0d8b22df-e396-4dc4-a985-7bf2dad982f7.png)

- 方差：[S（x，ε）越大→ 1 -  S（x，ε）越小 → 方差越靠近1越好，当≥1时，方差为0]

  ![image-20230201230608914](https://user-images.githubusercontent.com/91411874/216242200-a211568e-b140-4337-87b4-6fe3a2f5a849.png)

- 协方差：[根据总Loss，协方差越小越好]

![image-20230201230829674](https://user-images.githubusercontent.com/91411874/216242284-e1593e1b-7520-498b-9a8a-cd58c503bf51.png)

![image-20230201230846829](https://user-images.githubusercontent.com/91411874/216242315-8546282f-8ad5-4f4e-9f7e-8e4121d8e5c0.png)

- MSE：[根据总Loss，MSE越小越好]

![image-20230201230920926](https://user-images.githubusercontent.com/91411874/216242352-17844313-83b6-4620-8ee6-f98e5c4af9b7.png)

​	**结论**：**方差越大越好，协方差越小越好，MSE越小越好**

但根据我们的实验：原始样本+增强后的样本一起训练模型，loss只有分类loss，举个例子：在YELP二分类数据集，未增强模型在该数据集准确度Acc是70。


- Var_A：已增强模型A分类样本的方差
- O_MSE：未增强模型A和B分类之间的距离
- A_MSE：已增强模型A和B分类之间的距离

| 方法     | Acc  | 原始方差A | 原始方差B | 均值  | Var_A | Var_B | 均值  | O_MSE | A_MSE |
| -------- | ---- | --------- | --------- | ----- | ----- | ----- | ----- | ----- | ----- |
| 字符增强 | 81   | 0.452     | 0.436     | 0.409 | 0.289 | 0.279 | 0.284 | 0.019 | 0.123 |

- O_C_A：未增强模型A分类样本的协方差
- A_C_A：已增强模型A分类样本的协方差

| 方法     | Acc  | O_C_A | O_C_B | 均值  | A_C_A | A_C_B | 均值  |
| -------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- |
| 字符增强 | 81   | 0.291 | 0.303 | 0.297 | 0.383 | 0.384 | 0.383 |

根据上面数据，我们发现，**已增强模型相比于未增强模型，方差变小，协方差变大，MSE变大，与VICReg中结论恰好相反**

## 4.Loss指标

### Eval数据集

#### 4.1指标解释

（1）原方A：基线模型在A分类上的方差，原方B同理；（2）增方A：已增强模型在在A分类上的方差，增方B同理；

（3）OMA[O代表基线；M代表MSE；A代表A分类]：基线模型，原始样本和增强样本，在A分类上的MSE距离，OMB同理

（4）AMA[A代表增强；M代表MSE；A代表A分类]：已增强模型，原始样本和增强样本，在A分类上的MSE距离，AMA同理

（5）“+3Loss”：训练阶段，在分类Loss的基础上，额外添加均方、方差和协方差Loss

#### 4.2 规律

- 方差：纯增强模型方差 **<** 基线模型方差；纯增强+3Loss模型方差 **>** 基线模型方差
- MSE：纯增强+3Loss在MSE指标上**明显＜**纯增强模型；但纯增强模型在MSE指标上跟基线模型MSE指标没相关性；

| 方法    | Acc  | batch | 原方A | 原方B | 均值  | 增方A | 增方B | 均值  | OMA   | OMB   | 均值  | AMA   | AMB   | 均值  |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1       | 78   | 64    | 0.408 | 0.410 | 0.409 | 0.326 | 0.308 | 0.317 | 0.016 | 0.019 | 0.018 | 0.025 | 0.026 | 0.026 |
| 1+3Loss | 71   | 64    | 0.408 | 0.410 | 0.409 | 0.531 | 0.528 | 0.530 | 0.016 | 0.019 | 0.018 | 0.006 | 0.006 | 0.006 |
| 7       | 76   | 64    | 0.408 | 0.410 | 0.409 | 0.281 | 0.259 | 0.270 | 0.006 | 0.009 | 0.008 | 0.015 | 0.022 | 0.018 |
| 7+3Loss | 71   | 64    | 0.408 | 0.410 | 0.409 | 0.533 | 0.531 | 0.532 | 0.006 | 0.009 | 0.008 | 0.005 | 0.008 | 0.006 |
|         |      |       |       |       |       |       |       |       |       |       |       |       |       |       |
| 1       | 71   | **8** | 0.408 | 0.410 | 0.409 | 0.205 | 0.163 | 0.184 | 0.016 | 0.019 | 0.018 | 0.014 | 0.011 | 0.012 |
| 1+3Loss | 78   | **8** | 0.408 | 0.410 | 0.409 | 0.554 | 0.552 | 0.553 | 0.016 | 0.019 | 0.018 | 0.005 | 0.006 | 0.006 |
| 7       | 71   | **8** | 0.408 | 0.410 | 0.409 | 0.205 | 0.163 | 0.184 | 0.006 | 0.009 | 0.008 | 0.012 | 0.028 | 0.020 |
| 7+3Loss | 78   | **8** | 0.408 | 0.410 | 0.409 | 0.578 | 0.603 | 0.591 | 0.006 | 0.009 | 0.008 | 0.002 | 0.003 | 0.003 |

#### 4.1指标解释

（1）OCA[O:基线模型；C：协方差；A：分类A]：基线模型，在A分类上的协方差，OCB同理

（2）ACA[A:增强模型；C：协方差；A：分类A]：已增强模型，在A分类上的协方差，ACB同理

#### 4.1规律

- 协方差：纯增强模型和纯增强模型+3Loss模型的协方差值**均＞**基线模型的协方差值；并且，纯增强+3Loss模型的协方差值 **<** 纯增强模型的协方差值

| 方法    | Acc  | batch | OCA   | OCB   | 均值  | ACA   | ACB   | 均值  | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- | -------- | -------- | ---------- |
| 1       | 78   | 64    | 0.291 | 0.303 | 0.297 | 0.377 | 0.388 | 0.382 | 0.005    |          |          |            |
| 1+3Loss | 71   | 64    | 0.291 | 0.303 | 0.297 | 0.329 | 0.334 | 0.331 | 0.196    | 0.012    | 0.949    | 0.651      |
| 7       | 76   | 64    | 0.291 | 0.303 | 0.297 | 0.384 | 0.392 | 0.388 | 0.002    |          |          |            |
| 7+3Loss | 71   | 64    | 0.291 | 0.303 | 0.297 | 0.334 | 0.338 | 0.336 | 0.138    | 0.011    | 0.967    | 0.661      |
|         |      |       |       |       |       |       |       |       |          |          |          |            |
| 1       | 71   | **8** | 0.291 | 0.303 | 0.297 | 0.396 | 0.395 | 0.395 | 0        |          |          |            |
| 1+3Loss | 78   | **8** | 0.291 | 0.303 | 0.297 | 0.334 | 0.338 | 0.336 | 0.284    | 0.008    | 0.903    | 0.594      |
| 7       | 71   | **8** | 0.291 | 0.303 | 0.297 | 0.396 | 0.395 | 0.395 | 0        |          |          |            |
| 7+3Loss | 78   | **8** | 0.291 | 0.303 | 0.297 | 0.334 | 0.337 | 0.335 | 0.041    | 0.002    | 0.891    | 0.286      |

### （2）Train数据集

#### 4.2 规律（与Eval集的规律一样）

- 方差：纯增强模型方差 **<** 基线模型方差；纯增强+3Loss模型方差 **>** 基线模型方差
- MSE：纯增强+3Loss在MSE指标上**明显＜**纯增强模型；但纯增强模型在MSE指标上跟基线模型MSE指标没相关性；

| 方法    | Acc  | batch | 原方A | 原方B | 均值  | 增方A | 增方B | 均值  | OMA   | OMB   | 均值  | AMA   | AMB   | 均值  |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| 1       | 78   | 64    | 0.391 | 0.399 | 0.395 | 0.256 | 0.218 | 0.237 | 0.018 | 0.031 | 0.025 | 0.029 | 0.022 | 0.025 |
| 1+3Loss | 71   | 64    | 0.391 | 0.399 | 0.395 | 0.509 | 0.514 | 0.512 | 0.018 | 0.031 | 0.025 | 0.005 | 0.005 | 0.005 |
| 7       | 76   | 64    | 0.391 | 0.399 | 0.395 | 0.203 | 0.161 | 0.182 | 0.006 | 0.008 | 0.007 | 0.018 | 0.012 | 0.015 |
| 7+3Loss | 71   | 64    | 0.391 | 0.399 | 0.395 | 0.509 | 0.512 | 0.510 | 0.006 | 0.008 | 0.007 | 0.005 | 0.005 | 0.005 |
|         |      |       |       |       |       |       |       |       |       |       |       |       |       |       |
| 1       | 71   | **8** | 0.391 | 0.399 | 0.395 | 0.136 | 0.087 | 0.111 | 0.018 | 0.031 | 0.025 | 0.012 | 0.013 | 0.013 |
| 1+3Loss | 78   | **8** | 0.391 | 0.399 | 0.395 | 0.525 | 0.545 | 0.535 | 0.018 | 0.031 | 0.025 | 0.003 | 0.003 | 0.003 |
| 7       | 71   | **8** | 0.391 | 0.399 | 0.395 | 0.136 | 0.087 | 0.111 | 0.006 | 0.008 | 0.007 | 0.007 | 0.005 | 0.006 |
| 7+3Loss | 78   | **8** | 0.391 | 0.399 | 0.395 | 0.551 | 0.604 | 0.577 | 0.006 | 0.008 | 0.007 | 0.003 | 0.002 | 0.002 |

#### 4.2规律（与Eval集的规律一样）

- 协方差：纯增强模型和纯增强模型+3Loss模型的协方差值**均＞**基线模型的协方差值；并且，纯增强+3Loss模型的协方差值 < 纯增强模型的协方差值

| 方法    | Acc  | batch | OCA   | OCB   | 均值  | ACA   | ACB   | 均值  | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- | -------- | -------- | ---------- |
| 1       | 78   | 64    | 0.265 | 0.343 | 0.304 | 0.358 | 0.385 | 0.372 | 0.005    |          |          |            |
| 1+3Loss | 71   | 64    | 0.265 | 0.343 | 0.304 | 0.315 | 0.343 | 0.329 | 0.196    | 0.012    | 0.949    | 0.651      |
| 7       | 76   | 64    | 0.265 | 0.343 | 0.304 | 0.368 | 0.387 | 0.377 | 0.002    |          |          |            |
| 7+3Loss | 71   | 64    | 0.265 | 0.343 | 0.304 | 0.319 | 0.347 | 0.333 | 0.138    | 0.011    | 0.967    | 0.661      |
|         |      |       |       |       |       |       |       |       |          |          |          |            |
| 1       | 71   | **8** | 0.265 | 0.343 | 0.304 | 0.397 | 0.390 | 0.394 | 0        |          |          |            |
| 1+3Loss | 78   | **8** | 0.265 | 0.343 | 0.304 | 0.331 | 0.340 | 0.336 | 0.284    | 0.008    | 0.903    | 0.594      |
| 7       | 71   | **8** | 0.265 | 0.343 | 0.304 | 0.397 | 0.390 | 0.394 | 0        |          |          |            |
| 7+3Loss | 78   | **8** | 0.265 | 0.343 | 0.304 | 0.327 | 0.342 | 0.334 | 0.041    | 0.002    | 0.891    | 0.286      |

### （3）Loss变化

| Epoch | 方法 | Eval Acc | 分类L     |      | 方法    | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
| 1     | 1    | 0.55     | 0.66      |      | 1+3Loss | 0.50     | 2.30 | 0.669 | 0.006 | 1.13  | 0.50    |
| 2     |      | 0.56     | 0.56      |      |         | 0.55     | 2.19 | 0.597 | 0.007 | 1.04  | 0.55    |
| 3     |      | 0.65     | 0.33      |      |         | 0.55     | 2.09 | 0.518 | 0.008 | 0.96  | 0.60    |
| 4     |      | 0.73     | 0.15      |      |         | 0.58     | 1.95 | 0.372 | 0.010 | 0.93  | 0.64    |
| 5     |      | 0.66     | 0.036     |      |         | 0.71     | 1.80 | 0.196 | 0.012 | 0.94  | 0.65    |
| 6     |      | **0.78** | **0.005** |      |         | 0.70     | 1.73 | 0.046 | 0.013 | 1.01  | 0.67    |
| 7     |      | 0.75     | 0.002     |      |         | **0.71** | 1.69 | 0.028 | 0.011 | 0.994 | 0.66    |
| 8     |      | 0.75     | 0.001     |      |         | 0.68     | 1.66 | 0.036 | 0.008 | 0.971 | 0.64    |
| 9     |      | 0.76     | 0.001     |      |         | 0.66     | 1.64 | 0.039 | 0.007 | 0.956 | 0.64    |
| 10    |      | 0.65     | 0.001     |      |         | 0.61     | 1.63 | 0.036 | 0.008 | 0.942 | 0.64    |



| Epoch | 方法 | Eval Acc | 分类L     |      | 方法    | Eval Acc | 总L       | 分类L     | 均方L     | 方差L     | 协方差L   |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | --------- | --------- | --------- | --------- | --------- |
| 1     | 7    | 0.55     | 0.65      |      | 7+3Loss | 0.51     | 2.312     | 0.667     | 0.003     | 1.151     | 0.491     |
| 2     |      | 0.58     | 0.53      |      |         | 0.56     | 2.178     | 0.576     | 0.005     | 1.055     | 0.543     |
| 3     |      | 0.65     | 0.28      |      |         | 0.55     | 2.071     | 0.481     | 0.007     | 0.961     | 0.621     |
| 4     |      | 0.75     | 0.094     |      |         | 0.58     | 1.917     | 0.315     | 0.008     | 0.942     | 0.651     |
| 5     |      | 0.66     | 0.017     |      |         | 0.71     | 1.777     | 0.138     | 0.011     | 0.967     | 0.661     |
| 6     |      | 0.70     | 0.004     |      |         | 0.66     | 1.737     | 0.037     | 0.011     | 1.017     | 0.672     |
| 7     |      | **0.76** | **0.002** |      |         | **0.71** | **1.688** | **0.028** | **0.009** | **0.986** | **0.665** |
| 8     |      | 0.75     | 0.001     |      |         | 0.71     | 1.658     | 0.032     | 0.008     | 0.957     | 0.661     |
| 9     |      | 0.73     | 0.001     |      |         | 0.68     | 1.642     | 0.037     | 0.007     | 0.937     | 0.661     |
| 10    |      | 0.73     | 0         |      |         | 0.65     | 1.631     | 0.040     | 0.006     | 0.930     | 0.655     |

## 6.三次实验（增强方法：nac.OcrAug ；batch_size:64）--2023年3月7号

#### IMDB Train（随机种子：59）

- 方差：增+3L 方差 >  增方差
- MSE：增+3L MSE < 增MSE

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 | OMA  | OMB  | 均值 | AMA  | AMB  | 均值 |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增|60+16|0.193|0.290|0.242|0.366|0.395|0.380|0.011|0.058|0.034|0.021|0.022|0.021|
|增+3L|58|0.193|0.290|0.242|0.627|0.629|0.628|0.011|0.058|0.034|0.004|0.003|0.004|
|增|60+18|0.422|0.420|0.421|0.376|0.388|0.382|0.004|0.004|0.004|0.022|0.022|0.022|
|增+3L|61|0.422|0.420|0.421|0.616|0.614|0.615|0.004|0.004|0.004|0.004|0.005|0.004|
|增|65+21|0.441|0.439|0.440|0.458|0.452|0.455|0.004|0.005|0.004|0.008|0.012|0.010|
|增+3L| 66    |0.441|0.439|0.440|0.630|0.630|0.630|0.004|0.005|0.004|0.003|0.003|0.003|

- 协方差：增+3L 协方差 > 增 协方差 ；总得来说：增+3L协方差和增协方差均＞基线模型

| 方法 | Acc | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | -------- | -------- | ---------- | ---------- |
|增|60+16|0.371|0.386|0.379|0.370|0.377|0.373|0.157|0.021|1.243|0.747|
|增+3L|58|0.371|0.386|0.379|0.399|0.399|0.399|0.652|0.004|0.743|0.796|
|增|60+18|0.260|0.259|0.259|0.379|0.378|0.378|0.085|0.022|1.234|0.757|
|增+3L| 61    |0.260|0.259|0.259|0.392|0.392|0.392|0.668|0.004|0.769|0.783|
|增|65+21|0.284|0.285|0.285|0.316|0.321|0.319|0.380|0.010|1.094|0.632|
|增+3L|66|0.284|0.285|0.285|0.400|0.400|0.400|0.648|0.003|0.739|0.799|


- 原原A[原始模型；原始样本；A类]：**原始**模型，对**原始**样本，关于A分类的probability
- 原增A[原始模型；增强样本；A类]：原始模型，对增强样本，关于A分类的probability
- 增原A[增强模型；原始样本；A类]：**增强**模型，对**原始**样本，关于A分类的probability
- 增增A[增强模型；增强样本；A类]：增强模型，对增强样本，关于A分类的probability

| 方法 | 原原A | 原原B | 原增A | 原增B |      | 增原A | 增原B | 增增A | 增增B |
| ---- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ----- | ----- |
|增|(0.9957,0.0043)|(0.3317,0.6683)|(0.9956,0.0044)|(0.5384,0.4616)||(0.9426,0.0574)|(0.1566,0.8434)|(0.9612,0.0388)|(0.2334,0.7666)|
|增+3L|(0.9957,0.0043)|(0.3317,0.6683)|(0.9956,0.0044)|(0.5384,0.4616)||(0.5179,0.4821)|(0.4740,0.5260)|(0.5230,0.4770)|(0.4807,0.5193)|
|增|(0.5570,0.4430)|(0.4901,0.5099)|(0.5397,0.4603)|(0.4872,0.5128)||(0.9440,0.0560)|(0.0978,0.9022)|(0.9385,0.0615)|(0.0903,0.9097)|
|增+3L|(0.5570,0.4430)|(0.4901,0.5099)|(0.5397,0.4603)|(0.4872,0.5128)||(0.4985,0.5015)|(0.4738,0.5262)|(0.4994,0.5006)|(0.4720,0.5280)|
|增|(0.5221,0.4779)|(0.4313,0.5687)|(0.5064,0.4936)|(0.4334,0.5666)||(0.6983,0.3017)|(0.3245,0.6755)|(0.6784,0.3216)|(0.2986,0.7014)|
|增+3L|(0.5221,0.4779)|(0.4313,0.5687)|(0.5064,0.4936)|(0.4334,0.5666)||(0.5210,0.4790)|(0.4745,0.5255)|(0.5158,0.4842)|(0.4676,0.5324)|

#### YELP Train（随机种子：159）

- 方差：增+3L 方差 >  增方差
- MSE：增+3L MSE < 增MSE

| 方法  | Acc   | 原方A | 原方B | 均值  | 增方A | 增方B | 均值  | OMA   | OMB   | 均值  | AMA   | AMB   | 均值  |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
|增|65+21|0.436|0.392|0.414|0.340|0.262|0.301|0.012|0.019|0.016|0.034|0.034|0.034|
|增+3L| 56    |0.436|0.392|0.414|0.527|0.502|0.514|0.012|0.019|0.016|0.008|0.013|0.011|
|增| 71+4  |0.422|0.419|0.420|0.231|0.252|0.242|0.017|0.016|0.017|0.019|0.025|0.022|
|增+3L| 63    |0.422|0.419|0.420|0.623|0.624|0.624|0.017|0.016|0.017|0.006|0.006|0.006|
|增|68+23|0.443|0.407|0.425|0.254|0.204|0.229|0.010|0.019|0.015|0.020|0.021|0.020|
|增+3L| 66    |0.443|0.407|0.425|0.571|0.550|0.561|0.010|0.019|0.015|0.006|0.012|0.009|

- 协方差：增+3L协方差 < 增协方差; 增+3L协方差和增协方差均＞基线模型

| 方法  | Acc   | OCA   | OCB   | 均值  | ACA   | ACB   | 均值  | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- | -------- | -------- | ---------- |
|增|65+21|0.304|0.299|0.301|0.389|0.395|0.392|0.010|0.034|1.397|0.783|
|增+3L|56|0.304|0.299|0.301|0.355|0.335|0.345|0.679|0.011|0.963|0.689|
|增| 71+4  |0.295|0.310|0.303|0.392|0.400|0.396|0.003|0.022|1.515|0.792|
|增+3L|63|0.295|0.310|0.303|0.397|0.397|0.397|0.644|0.006|0.751|0.793|
|增|68+23|0.310|0.313|0.312|0.399|0.395|0.397|0.002|0.020|1.539|0.793|
|增+3L|66|0.310|0.313|0.312|0.366|0.359|0.362|0.669|0.009|0.872|0.726|


| 方法  | 原原A           | 原原B           | 原增A           | 原增B           |      | 增原A           | 增原B           | 增增A           | 增增B           |
| ----- | --------------- | --------------- | --------------- | --------------- | ---- | --------------- | --------------- | --------------- | --------------- |
|增|(0.5887,0.4113)|(0.2415,0.7585)|(0.5394,0.4606)|(0.2695,0.7305)||(0.9861,0.0139)|(0.0052,0.9948)|(0.9850,0.0150)|(0.0035,0.9965)|
|增+3L|(0.5887,0.4113)|(0.2415,0.7585)|(0.5394,0.4606)|(0.2695,0.7305)||(0.5088,0.4912)|(0.4926,0.5074)|(0.5037,0.4963)|(0.4896,0.5104)|
|增|(0.7057,0.2943)|(0.2874,0.7126)|(0.6430,0.3570)|(0.3171,0.6829)||(0.9990,0.0010)|(0.0045,0.9955)|(0.9990,0.0010)|(0.0038,0.9962)|
|增+3L|(0.7057,0.2943)|(0.2874,0.7126)|(0.6430,0.3570)|(0.3171,0.6829)||(0.5370,0.4630)|(0.4818,0.5182)|(0.5305,0.4695)|(0.4828,0.5172)|
|增|(0.5297,0.4703)|(0.2125,0.7875)|(0.4885,0.5115)|(0.2350,0.7650)||(0.9976,0.0024)|(0.0018,0.9982)|(0.9965,0.0035)|(0.0015,0.9985)|
|增+3L|(0.5297,0.4703)|(0.2125,0.7875)|(0.4885,0.5115)|(0.2350,0.7650)||(0.5124,0.4876)|(0.4827,0.5173)|(0.5104,0.4896)|(0.4872,0.5128)|

#### IMDB Eval（随机种子：59）

- 方差规律：增+3L 方差 > 增方差

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- |
|增|0.767|0.236|0.271|0.254|0.394|0.401|0.398|
|增+3L|0.583|0.236|0.271|0.254|0.626|0.627|0.627|
|增|0.783|0.427|0.422|0.424|0.411|0.400|0.406|
|增+3L|0.617|0.427|0.422|0.424|0.615|0.613|0.614|
|增|0.867|0.442|0.425|0.434|0.461|0.446|0.453|
|增+3L|0.667|0.442|0.425|0.434|0.630|0.625|0.628|

- 协方差：增+3L  协方差 > 增协方差;  总得来说：增+3L协方差和增协方差均＞基线模型

| 方法 | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增|0.767|0.373|0.379|0.376|0.366|0.372|0.369|
|增+3L|0.583|0.373|0.379|0.376|0.398|0.398|0.398|
|增|0.783|0.262|0.260|0.261|0.378|0.372|0.375|
|增+3L|0.617|0.262|0.260|0.261|0.391|0.392|0.392|
|增|0.867|0.284|0.269|0.277|0.318|0.302|0.310|
|增+3L|0.667|0.284|0.269|0.277|0.400|0.398|0.399|

#### YELP Eval（随机种子：159）

- 方差规律：增+3L方差 **>** 基线模型方差

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- |
|增|0.867|0.431|0.430|0.430|0.363|0.322|0.343|
|增+3L|0.567|0.431|0.430|0.430|0.521|0.525|0.523|
|增|0.750|0.416|0.424|0.420|0.279|0.284|0.282|
|增+3L|0.633|0.416|0.424|0.420|0.622|0.623|0.623|
|增|0.917|0.442|0.428|0.435|0.262|0.240|0.251|
|增+3L|0.667|0.442|0.428|0.435|0.565|0.560|0.563|

- 协方差：增+3L协方差 < 增协方差; 增+3L协方差和增协方差均＞基线模型

| 方法 | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增|0.867|0.300|0.303|0.301|0.390|0.390|0.390|
|增+3L|0.567|0.300|0.303|0.301|0.345|0.349|0.347|
|增|0.750|0.286|0.306|0.296|0.388|0.387|0.388|
|增+3L|0.633|0.286|0.306|0.296|0.396|0.396|0.396|
|增|0.917|0.311|0.312|0.312|0.397|0.397|0.397|
|增+3L|0.667|0.311|0.312|0.312|0.366|0.362|0.364|

#### Loss变化（IMDB）
| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.617|0.726||增+3L|0.467|27.262|0.707|0.004|1.033|0.650|
|1|增|0.500|0.631||增+3L|0.517|23.230|0.701|0.005|0.867|0.734|
|2|增|0.683|0.559||增+3L|0.483|22.098|0.694|0.005|0.821|0.763|
|3|增|0.667|0.416||增+3L|0.483|21.425|0.686|0.004|0.794|0.776|
|4|增|**0.767**|**0.226**||增+3L|0.550|21.012|0.681|0.004|0.778|0.781|
|5|增|0.550|0.108||增+3L|0.550|20.719|0.675|0.004|0.767|0.784|
|6|增|0.667|0.062||增+3L|0.533|20.487|0.665|0.004|0.758|0.788|
|7|增|0.683|0.088||增+3L|0.567|20.325|0.663|0.004|0.751|0.792|
|8|增|0.517|0.014||增+3L|**0.583**|20.194|**0.654**|**0.004**|**0.746**|**0.795**|
|9|增|0.667|0.039||增+3L|0.583|20.085|0.643|0.004|0.742|0.797|

| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.683|0.722||增+3L|0.600|27.248|0.704|0.004|1.032|0.651|
|1|增|0.517|0.616||增+3L|0.500|23.165|0.700|0.005|0.864|0.735|
|2|增|0.700|0.542||增+3L|0.600|22.045|0.683|0.005|0.819|0.764|
|3|增|0.767|0.384||增+3L|0.583|21.370|0.678|0.005|0.792|0.776|
|4|增|**0.783**|**0.189**||增+3L|**0.617**|20.958|**0.672**|**0.004**|**0.776**|**0.782**|
|5|增|0.617|0.062||增+3L|0.600|20.699|0.662|0.004|0.766|0.785|
|6|增|0.650|0.035||增+3L|0.567|20.453|0.660|0.004|0.757|0.788|
|7|增|0.750|0.028||增+3L|0.583|20.291|0.649|0.004|0.750|0.793|
|8|增|0.617|0.002||增+3L|0.583|20.171|0.646|0.004|0.746|0.795|
|9|增|0.750|0.020||增+3L|0.583|20.061|0.638|0.004|0.742|0.797|

| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.533|0.757||增+3L|0.600|27.160|0.699|0.004|1.028|0.652|
|1|增|0.500|0.628||增+3L|0.633|23.178|0.694|0.005|0.865|0.735|
|2|增|0.700|0.593||增+3L|0.550|22.027|0.687|0.005|0.818|0.763|
|3|增|**0.867**|**0.491**||增+3L|0.583|21.375|0.682|0.005|0.792|0.776|
|4|增|0.833|0.306||增+3L|0.633|20.943|0.675|0.004|0.775|0.781|
|5|增|0.783|0.158||增+3L|0.600|20.691|0.668|0.004|0.766|0.784|
|6|增|0.833|0.028||增+3L|0.633|20.467|0.664|0.004|0.757|0.788|
|7|增|0.867|0.010||增+3L|0.617|20.312|0.660|0.004|0.751|0.792|
|8|增|0.800|0.002||增+3L|0.600|20.194|0.654|0.004|0.746|0.794|
|9|增|0.650|0.002||增+3L|**0.667**|20.078|**0.647**|**0.004**|**0.742**|**0.797**|

#### Loss变化（YELP）
| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.550|0.690||增+3L|**0.567**|29.026|**0.687**|**0.008**|**1.102**|**0.593**|
|1|增|0.583|0.544||增+3L|0.483|24.762|0.675|0.010|0.926|0.703|
|2|增|0.617|0.409||增+3L|0.500|23.087|0.664|0.009|0.858|0.735|
|3|增|0.750|0.241||增+3L|0.517|21.978|0.660|0.009|0.813|0.764|
|4|增|0.833|0.101||增+3L|0.517|21.544|0.656|0.008|0.797|0.774|
|5|增|**0.867**|**0.025**||增+3L|0.533|21.192|0.640|0.008|0.783|0.777|
|6|增|0.817|0.006||增+3L|0.550|20.933|0.633|0.008|0.772|0.782|
|7|增|0.817|0.002||增+3L|0.550|20.658|0.617|0.008|0.763|0.786|
|8|增|0.767|0.001||增+3L|0.533|20.469|0.612|0.007|0.756|0.791|
|9|增|0.767|0.001||增+3L|0.467|20.339|0.605|0.007|0.751|0.795|

| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.683|0.737||增+3L|0.583|29.014|0.694|0.010|1.099|0.593|
|1|增|0.500|0.601||增+3L|0.600|24.672|0.681|0.011|0.920|0.705|
|2|增|0.700|0.555||增+3L|0.500|23.120|0.679|0.010|0.858|0.737|
|3|增|0.700|0.403||增+3L|0.483|22.025|0.673|0.010|0.813|0.763|
|4|增|0.733|0.174||增+3L|0.567|21.579|0.668|0.009|0.796|0.772|
|5|增|0.650|0.057||增+3L|0.550|21.194|0.663|0.009|0.781|0.779|
|6|增|0.717|0.014||增+3L|0.617|20.865|0.659|0.008|0.769|0.784|
|7|增|**0.750**|**0.002**||增+3L|0.600|20.634|0.647|0.007|0.761|0.788|
|8|增|0.717|0.005||增+3L|**0.633**|20.481|**0.648**|**0.007**|**0.755**|**0.791**|
|9|增|0.700|0.001||增+3L|0.617|20.348|0.642|0.007|0.750|0.794|

| Epoch | 方法 | Eval Acc | 分类L | | 方法 | Eval Acc | 总L  | 分类L | 均方L | 方差L | 协方差L |
| ----- | ---- | -------- | --------- | ---- | ------- | -------- | ---- | ----- | ----- | ----- | ------- |
|0|增|0.650|0.705||增+3L|0.650|28.815|0.694|0.008|1.093|0.592|
|1|增|0.667|0.566||增+3L|**0.667**|24.737|**0.679**|**0.010**|**0.924**|**0.705**|
|2|增|0.700|0.440||增+3L|0.633|23.163|0.666|0.010|0.861|0.734|
|3|增|0.850|0.255||增+3L|0.650|22.048|0.657|0.010|0.815|0.762|
|4|增|0.867|0.087||增+3L|0.633|21.489|0.648|0.009|0.794|0.772|
|5|增|0.850|0.014||增+3L|0.533|21.316|0.643|0.010|0.786|0.779|
|6|增|**0.917**|**0.004**||增+3L|0.550|20.910|0.625|0.009|0.771|0.784|
|7|增|0.833|0.002||增+3L|0.533|20.747|0.617|0.008|0.765|0.788|
|8|增|0.833|0.001||增+3L|0.600|20.502|0.604|0.008|0.757|0.791|
|9|增|0.800|0.001||增+3L|0.633|20.398|0.601|0.008|0.752|0.793|

## 7.T-SNE

#### 7.1（不加降维层）

- IMDB数据集

![Train_IMDB_Base_Model_1](https://user-images.githubusercontent.com/91411874/224636068-b453cf9f-a664-4ae8-bc7d-c297ee559b46.png)
![Train_IMDB_Aug_1](https://user-images.githubusercontent.com/91411874/224636099-1d45a0fc-896d-4895-9c61-bc637350c325.png)
![Train_IMDB_Aug+3Loss_1](https://user-images.githubusercontent.com/91411874/224636108-67da5fc9-b1bb-47d1-9b9c-e95bbf4655ec.png)

![Train_IMDB_Base_Model_2](https://user-images.githubusercontent.com/91411874/224636075-3eb7c259-e9bf-4d28-9a95-fb5e062195d4.png)
![Train_IMDB_Aug_2](https://user-images.githubusercontent.com/91411874/224636104-b09c00ce-ad1a-4f9d-84b6-f74df71dc08a.png)
![Train_IMDB_Aug+3Loss_2](https://user-images.githubusercontent.com/91411874/224636114-10b00c8a-1419-46ed-9f5a-4d938d2a2fb9.png)

![Train_IMDB_Base_Model_3](https://user-images.githubusercontent.com/91411874/224636079-022588bf-51e0-4a59-a9d3-f421ad278713.png)
![Train_IMDB_Aug_3](https://user-images.githubusercontent.com/91411874/224636095-42e6a204-66e3-4128-80f2-2cc7d059384a.png)
![Train_IMDB_Aug+3Loss_3](https://user-images.githubusercontent.com/91411874/224636117-588020af-f031-445b-88dd-1c4e4bfcb3c8.png)

- YELP数据集

![Train_YELP_Base_Model_1](https://user-images.githubusercontent.com/91411874/224636370-e4ff6b69-a3d2-411e-8d36-432cd194a451.png)
![Train_YELP_Aug_1](https://user-images.githubusercontent.com/91411874/224636392-4f8ee72c-0a7c-4b80-9902-8fb43d284ac7.png)
![Train_YELP_Aug+3Loss_1](https://user-images.githubusercontent.com/91411874/224636416-12fa8fe9-1350-4416-a911-7d10a9ddbfc7.png)


![Train_YELP_Base_Model_2](https://user-images.githubusercontent.com/91411874/224636376-a69d2f39-1bfa-4aae-bf94-c4f1fc76e951.png)
![Train_YELP_Aug_2](https://user-images.githubusercontent.com/91411874/224636396-2effc791-c724-4c02-accc-1a01b5b7a705.png)
![Train_YELP_Aug+3Loss_2](https://user-images.githubusercontent.com/91411874/224636422-42ee9530-933f-4be9-80b6-bc869dfbfac6.png)


![Train_YELP_Base_Model_3](https://user-images.githubusercontent.com/91411874/224636379-465418e1-b3b0-4397-a4c9-34855ec21d69.png)
![Train_YELP_Aug_3](https://user-images.githubusercontent.com/91411874/224636402-d0bdc9e5-55bf-4924-9641-95848d840408.png)
![Train_YELP_Aug+3Loss_3](https://user-images.githubusercontent.com/91411874/224636425-64f92352-26c6-476a-992d-0b9af2d1203e.png)

#### 7.2 加降维层

 ```python
  class BertForSequenceClassification(BertPreTrainedModel):
      def __init__(self, config):
          super().__init__(config)
          self.num_labels = 2
          self.config = config
          self.bert = BertModel(config)
          classifier_dropout = (
              config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob
          )
          self.dropout = nn.Dropout(classifier_dropout)
          self.classifier_PCD = nn.Linear(config.hidden_size, self.num_labels) #768 →→ 2
          self.classifier = nn.Linear(self.num_labels, self.num_labels) #2 →→ 2
          self.init_weights()
          
      def forward(
          self,
          input_ids=None,
          attention_mask=None,
          token_type_ids=None,
          labels=None
      ):
          outputs = self.bert(
              input_ids,
              attention_mask=attention_mask,
              token_type_ids=token_type_ids,
          )
  
          labels = labels.view(labels.size(0))
  
          output = outputs[0]
          mean_output = torch.mean(outputs[0][:, 1:, :], dim=1) #平均池化
          logits_PCD = self.classifier_PCD(mean_output) # 降维，画图
          logits = self.classifier(logits_PCD) #作分类
          cls_loss = loss_function(logits, labels)
  ```
  
  - IMDB数据集（实心）
 
![Train_IMDB_Base_Model_1](https://user-images.githubusercontent.com/91411874/225606354-20708c06-ffe2-421d-9dc7-0ac10a896ac3.png)
![Train_IMDB_Aug_1](https://user-images.githubusercontent.com/91411874/225606410-3188d8f8-6ecd-4e45-8126-be70009d057a.png)
![Train_IMDB_Aug+3Loss_1](https://user-images.githubusercontent.com/91411874/225606431-27b018de-e568-4004-9acd-44ec02dc8d0f.png)

![Train_IMDB_Base_Model_2](https://user-images.githubusercontent.com/91411874/225606364-bfa9f0d0-b693-4d90-9e49-4828fd136a97.png)
![Train_IMDB_Aug_2](https://user-images.githubusercontent.com/91411874/225606415-fa84104a-0b0f-4a6b-bc02-e55acf54bf88.png)
![Train_IMDB_Aug+3Loss_2](https://user-images.githubusercontent.com/91411874/225606435-af450056-7122-478a-9175-403eacd3f481.png)

![Train_IMDB_Base_Model_3](https://user-images.githubusercontent.com/91411874/225606365-f4b8b338-6d73-4714-a012-d6ad5eddecb7.png)
![Train_IMDB_Aug_3](https://user-images.githubusercontent.com/91411874/225606424-286f55d7-0c99-4f81-9d74-a3f0e5407e2a.png)
![Train_IMDB_Aug+3Loss_3](https://user-images.githubusercontent.com/91411874/225606438-efea23a0-512e-4111-923b-a50607525b49.png)

  - YELP数据集（实心）
  
 
![Train_YELP_Base_Model_1](https://user-images.githubusercontent.com/91411874/225606893-85f2c266-0174-4a1e-bfd7-3e1e4ab63e26.png)
![Train_YELP_Aug_1](https://user-images.githubusercontent.com/91411874/225606916-6cb41be7-8731-4a16-8ccd-31fd829aba48.png)
![Train_YELP_Aug+3Loss_1](https://user-images.githubusercontent.com/91411874/225606946-913bbd84-b313-4677-a354-fd0068ad0054.png)

![Train_YELP_Base_Model_2](https://user-images.githubusercontent.com/91411874/225606898-ab1c997c-3366-478f-8e29-839d33dd71a5.png)
![Train_YELP_Aug_2](https://user-images.githubusercontent.com/91411874/225606921-1cafe9d7-2db8-4d3c-8f16-85dc04c9d2a6.png)
![Train_YELP_Aug+3Loss_2](https://user-images.githubusercontent.com/91411874/225606953-b550e918-8d71-47af-b08e-967957ebdb6c.png)

![Train_YELP_Base_Model_3](https://user-images.githubusercontent.com/91411874/225606902-683eb47e-4bcc-4e05-8ea5-30ad3ea4a762.png)
![Train_YELP_Aug_3](https://user-images.githubusercontent.com/91411874/225606926-178390f6-8558-491e-aab3-12eeccaf0b31.png)
![Train_YELP_Aug+3Loss_3](https://user-images.githubusercontent.com/91411874/225606957-f91c8871-559b-4c8d-ac3d-c833a70ffe1f.png)

- IMDB数据集（空心）

![Train_IMDB_Base_Model_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158437-9f5a7a58-30c7-4315-8bc5-bb4f9eb95c88.png)
![Train_IMDB_Aug_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158423-592539fd-49a5-468d-9bef-d11be9ac568d.png)
![Train_IMDB_Aug+3Loss_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158429-723fc553-bb19-428c-b0d7-0e9099a3292c.png)

![Train_IMDB_Base_Model_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158440-e1633c7f-771e-4a4a-a4dc-cb5f9eb44571.png)
![Train_IMDB_Aug_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158425-7a22fab7-ed95-43bb-aec8-0f977eca7ddc.png)
![Train_IMDB_Aug+3Loss_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158431-3e04c3ad-d4de-4fc5-aad2-dec75d6acd98.png)

![Train_IMDB_Base_Model_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158441-3263af2c-bdfe-4bac-85e9-8b800604884c.png)
![Train_IMDB_Aug_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158426-20e2f247-58aa-495c-a1e6-fa1a4a6b4331.png)
![Train_IMDB_Aug+3Loss_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158433-ec50f91a-0980-4a2f-9343-ae23dfe5cf7c.png)

- YELP数据集（空心）

![Train_YELP_Base_Model_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158507-7739b6e6-8ab6-4433-98f1-064a9ae36b79.png)
![Train_YELP_Aug_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158497-2960e4de-af74-4aa5-a868-76bad7724059.png)
![Train_YELP_Aug+3Loss_1_no_softmax](https://user-images.githubusercontent.com/91411874/226158502-fc007b5a-1c9b-4cfe-981b-aa740f7db776.png)

![Train_YELP_Base_Model_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158508-4ed80568-93c5-4093-9ae5-c32f2228e112.png)
![Train_YELP_Aug_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158500-ea44efc6-c4e8-4878-901c-499ad3d5d1c5.png)
![Train_YELP_Aug+3Loss_2_no_softmax](https://user-images.githubusercontent.com/91411874/226158503-817d18ec-6716-45ee-ad72-5cbe2df6323f.png)

![Train_YELP_Base_Model_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158509-b180ab28-3f1c-4f37-ab98-766f23154097.png)
![Train_YELP_Aug_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158501-d1207eb1-8a23-4c3a-9e76-0eef06dce2af.png)
![Train_YELP_Aug+3Loss_3_no_softmax](https://user-images.githubusercontent.com/91411874/226158506-02dbbac0-247b-4ee6-9743-c74a9b0fce3e.png)


## 8：方差，协方差，MSE和对比学习Loss

- IMDB（SEED：59）

  - 增：原始样本和增强样本一起训练

  - 原：只用原始样本训练

  - 增+variance ：训练的时候，variance loss 和 分类 loss系数为1；covariance loss和mse loss系数为0


  - 增+（variance-0.434）：把代码原来1-variance改成variance - 原始模型的variance ；variance loss 和 分类 loss系数为1；covariance loss和mse loss系数为0


  - 增+3L：训练的时候，variance loss、covariance loss和mse loss的系数分别是：25,25,1


  - 增+3L（variance-0.434）：把代码原来1-variance改成variance - 原始模型的variance ；variance loss、covariance loss和mse loss的系数分别是：25,25,1


  - 增+contrastive ：分类loss和对比学习loss，系数分别是1,1

  

  | 方法 | Acc  | 方法 | Acc  | 方法          | Acc  | 方法   | Acc  | 方法           | Acc  |
  | ---- | ---- | ---- | ---- | ------------- | ---- | ------ | ---- | -------------- | ---- |
  | 原   | 81   | 增   | 85   | 增+covariance | 56   | 增+mse | 86   | 增+contrastive | 70   |
  | 原   | 75   | 增   | 78   | 增+covariance | 50   | 增+mse | 75   | 增+contrastive | 68   |
  | 原   | 83   | 增   | 83   | 增+covariance | 58   | 增+mse | 81   | 增+contrastive | 78   |

  | 方法  | Acc  | 方法                    | Acc  | 方法        | Acc  | 方法                  | Acc  |
  | ----- | ---- | ----------------------- | ---- | ----------- | ---- | --------------------- | ---- |
  | 增+3L | 51   | 增+3L（variance-0.434） | 60   | 增+variance | 63   | 增+（variance-0.434） | 73   |
  | 增+3L | 58   | 增+3L（variance-0.085） | 50   | 增+variance | 65   | 增+（variance-0.085） | 50   |
  | 增+3L | 53   | 增+3L（variance-0.160)  | 50   | 增+variance | 60   | 增+（variance-0.160） | 50   |

  

- YELP（SEED：159）

  | 方法 | Acc  | 方法 | Acc  | 方法          | Acc  | 方法   | Acc  | 方法           | Acc  |
  | ---- | ---- | ---- | ---- | ------------- | ---- | ------ | ---- | -------------- | ---- |
  | 原   | 78   | 增   | 80   | 增+covariance | 51   | 增+mse | 71   | 增+contrastive | 65   |
  | 原   | 73   | 增   | 66   | 增+covariance | 50   | 增+mse | 71   | 增+contrastive | 66   |
  | 原   | 86   | 增   | 88   | 增+covariance | 50   | 增+mse | 90   | 增+contrastive | 80   |

| 方法  | Acc  | 方法                    | Acc  | 方法        | Acc  | 方法                  | Acc  |
| ----- | ---- | ----------------------- | ---- | ----------- | ---- | --------------------- | ---- |
| 增+3L | 55   | 增+3L（variance-0.402） | 57   | 增+variance | 50   | 增+（variance-0.402） | 83   |
| 增+3L | 60   | 增+3L（variance-0.164） | 50   | 增+variance | 63   | 增+（variance-0.164） | 50   |
| 增+3L | 60   | 增+3L（variance-0.391） | 50   | 增+variance | 63   | 增+（variance-0.391） | 85   |

## 9 2021-2022年增强方法，在三个指标上的比较

## IMDB-Train

#### 指标解释

（1）原方A：基线模型在A分类上的方差，原方B同理；增方A：已增强模型在在A分类上的方差，增方B同理；

（2）OMA[O代表基线；M代表MSE；A代表A分类]：基线模型，原始样本和增强样本，在A分类上的MSE距离，OMB同理

（3）AMA[A代表增强；M代表MSE；A代表A分类]：已增强模型，原始样本和增强样本，在A分类上的MSE距离，AMA同理

   (4)  O_MSE：原始模型在原始样本上，A和B类之间的MSE距离；A_MSE：增强模型在原始样本上，A和B类之间的MSE距离；

#### 规律

- 方差：增+3L 方差 >  增方差
- MSE：增+3L MSE < 增MSE

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 | OMA  | OMB  | 均值 | AMA  | AMB  | 均值 | O_MSE | O_MSE |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增(AEDA)|**0.850**|0.428|0.440|0.434|0.211|0.219|0.215|0.009|0.011|0.010|0.006|0.006|0.006|0.002|**1.259**|
|增(AEDA)+VIC_Loss|0.517|0.428|0.440|0.434|0.628|0.629|0.628|0.009|0.011|0.010|0.004|0.004|0.004|0.002|0.000|
|增(BERT)|0.817|0.428|0.440|0.434|0.264|0.276|0.270|0.001|0.001|0.001|0.019|0.014|0.017|0.002|0.640|
|增(BERT)+VIC_Loss|0.567|0.428|0.440|0.434|0.628|0.629|0.628|0.001|0.001|0.001|0.003|0.003|0.003|0.002|0.000|
|增(MTV)|0.800|0.428|0.440|0.434|0.337|0.342|0.340|0.033|0.036|0.035|0.112|0.127|0.119|0.002|0.320|
|增(MTV)+VIC_Loss|0.517|0.428|0.440|0.434|0.545|0.550|0.547|0.033|0.036|0.035|0.024|0.024|0.024|0.002|0.001|
|增(Double_Mix)|0.700| 0.428 | 0.440 | 0.434 |0.439|0.447|0.443|0.050|0.051|0.050|0.102|0.125|0.113|0.001|0.035|
|||||||||||||||||
|增(AEDA)|0.767|0.102|0.067|0.085|0.393|0.385|0.389|0.860|0.005|0.432|0.042|0.024|0.033|1.197|0.173|
|增(BERT)|**0.800**|0.102|0.067|0.085|0.358|0.327|0.342|0.017|0.001|0.009|0.020|0.014|0.017|1.197|**0.275**|
|增(MTV)|0.733|0.102|0.067|0.085|0.271|0.265|0.268|1.244|0.029|0.636|0.065|0.070|0.068|1.197|0.742|
|增(Double_Mix)|0.700|0.102|0.067|0.085|0.321|0.239|0.280|1.232|0.033|0.633|0.552|0.135|0.343|1.197|0.448|
|||||||||||||||||
|增(AEDA)|**0.833**|0.140|0.180|0.160|0.198|0.207|0.202|0.016|0.098|0.057|0.003|0.003|0.003|0.681|1.377|
|增(BERT)|**0.833**|0.140|0.180|0.160|0.314|0.283|0.298|0.004|0.016|0.010|0.028|0.011|0.020|0.681|0.461|
|增(MTV)|**0.833**|0.140|0.180|0.160|0.246|0.241|0.244|0.174|0.228|0.201|0.104|0.044|0.074|0.681|0.858|
|增(Double_Mix)|0.750|0.140|0.180|0.160|0.450|0.448|0.449|0.191|0.200|0.195|0.076|0.073|0.074|0.681|0.010|

#### 指标解释

（1）OCA[O:基线模型；C：协方差；A：分类A]：基线模型，在A分类上的协方差，OCB同理

（2）ACA[A:增强模型；C：协方差；A：分类A]：已增强模型，在A分类上的协方差，ACB同理

#### 规律

- 协方差：增+3L协方差和增协方差均＞基线模型

| 方法 | Acc  | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | -------- | -------- | -------- | ---------- |
|增(AEDA)|**0.850**|0.269|0.281|0.275|0.406|0.404|0.405|          |          |          |            |
|增(AEDA)+VIC_Loss|0.517|0.269|0.281|0.275|0.398|0.399|0.399|0.693|0.004|0.743|0.796|
|增(BERT)|0.817|0.269|0.281|0.275|0.392|0.387|0.389|          |          |          |            |
|增(BERT)+VIC_Loss|0.567|0.269|0.281|0.275|0.399|0.399|0.399|0.693|0.003|0.743|0.796|
|增(MTV)|0.800|0.269|0.281|0.275|0.383|0.381|0.382|||||
|增(MTV)+VIC_Loss|0.517|0.269|0.281|0.275|0.357|0.363|0.360|0.693|0.024|0.898|0.723|
|增(Double_Mix)|0.700|0.274|0.279|0.277|0.319|0.355|0.337|0.452|          |          |            |
|||||||||||||
|增(AEDA)|0.767|0.407|0.400|0.403|0.385|0.375|0.380|0.648|          |          |            |
|增(BERT)|0.800|0.407|0.400|0.403|0.388|0.377|0.382|0.638|          |          |            |
|增(MTV)|0.733|0.407|0.400|0.403|0.400|0.392|0.396|0.578|          |          |            |
|增(Double_Mix)|0.700|0.407|0.400|0.403|0.358|0.354|0.356|1.457|          |          |            |
|||||||||||||
|增(AEDA)|0.833|0.400|0.395|0.397|0.409|0.407|0.408|0.498|          |          |            |
|增(BERT)|0.833|0.400|0.395|0.397|0.391|0.381|0.386|0.620|          |          |            |
|增(MTV)|0.833|0.400|0.395|0.397|0.403|0.393|0.398|0.572|          |          |            |
|增(Double_Mix)|0.750|0.400|0.395|0.397|0.303|0.318|0.311|0.601|          |          |            |

### YELP-Train

- 方差：增+3L 方差 >  增方差
- MSE：增+3L MSE < 增MSE

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 | OMA  | OMB  | 均值 | AMA  | AMB  | O_MSE | A_MSE |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增(AEDA)|0.783|0.416|0.388|0.402|0.209|0.205|0.207|0.011|0.013|0.012|0.007|0.018|0.009|1.252|
|增(AEDA)+VIC_Loss|0.533|0.416|0.388|0.402|0.610|0.603|0.606|0.011|0.013|0.012|0.008|0.010|0.009|0.002|
|增(BERT)|0.800|0.416|0.388|0.402|0.266|0.218|0.242|0.005|0.006|0.006|0.035|0.010|0.009|0.910|
|增(BERT)+VIC_Loss|0.550|0.416|0.388|0.402|0.611|0.603|0.607|0.005|0.006|0.006|0.007|0.010|0.009|0.002|
|增(MTV)|0.750|0.416|0.388|0.402|0.235|0.216|0.226|0.038|0.038|0.038|0.076|0.039|0.009|1.012|
|增(MTV)+VIC_Loss|0.600|0.416|0.388|0.402|0.615|0.607|0.611|0.038|0.038|0.038|0.012|0.015|0.009|0.003|
|增(Double_Mix)|**0.850**|0.416|0.388|0.402|0.315|0.223|0.269|0.053|0.045|0.049|0.194|0.123|0.159|0.009|
||||||||||||||||
|增(AEDA)|0.633|0.201|0.127|0.164|0.194|0.211|0.203|0.036|0.020|0.028|0.004|0.003|0.003|0.757|
|增(BERT)|0.633|0.201|0.127|0.164|0.287|0.283|0.285|0.032|0.014|0.023|0.029|0.031|0.030|0.757|
|增(MTV)|0.650|0.201|0.127|0.164|0.245|0.285|0.265|0.299|0.160|0.229|0.071|0.131|0.101|0.757|
|增(Double_Mix)|**0.833**|0.201|0.127|0.164|0.279|0.235|0.257|0.459|0.093|0.276|0.159|0.145|0.152|0.757|
||||||||||||||||
|增(AEDA)|0.867|0.407|0.374|0.391|0.225|0.215|0.220|0.008|0.008|0.008|0.012|0.011|0.011|0.004|
|增(BERT)|0.850|0.407|0.374|0.391|0.210|0.204|0.207|0.001|0.004|0.003|0.004|0.003|0.004|0.004|
|增(MTV)|0.850|0.407|0.374|0.391|0.217|0.207|0.212|0.029|0.028|0.029|0.070|0.013|0.041|0.004|
|增(Double_Mix)|**0.850**|0.407|0.374|0.391|0.220|0.187|0.204|0.040|0.033|0.037|0.359|0.108|0.234|0.004|


- 协方差：增+3L协方差和增协方差均＞基线模型

| 方法 | Acc  | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 | 分类Loss | 均方Loss | 方差Loss | 协方差Loss |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | -------- | -------- | -------- | ---------- |
|增(AEDA)|0.783|0.260|0.254|0.257|0.407|0.404|0.406|0.516|          |          |            |
|增(AEDA)+VIC_Loss|0.533|0.260|0.254|0.257|0.390|0.387|0.389|0.693|0.009|0.786|0.777|
|增(BERT)|0.800|0.260|0.254|0.257|0.403|0.400|0.401|0.562|          |          |            |
|增(BERT)+VIC_Loss|0.550|0.260|0.254|0.257|0.390|0.386|0.388|0.693|0.008|0.786|0.776|
|增(MTV)|0.750|0.260|0.254|0.257|0.403|0.403|0.403|0.531|          |          |            |
|增(MTV)+VIC_Loss|0.600|0.260|0.254|0.257|0.392|0.389|0.390|0.693|0.013|0.776|0.782|
|增(Double_Mix)|0.850|0.260|0.254|0.257|0.351|0.377|0.364|0.138|          |          |            |
|||||||||||||
|增(AEDA)|0.633|0.397|0.384|0.390|0.407|0.404|0.406|0.509|          |          |            |
|增(BERT)|0.633|0.397|0.384|0.390|0.368|0.385|0.376|0.614|          |          |            |
|增(MTV)|0.650|0.397|0.384|0.390|0.369|0.387|0.378|0.612|          |          |            |
|增(Double_Mix)|0.833|0.397|0.384|0.390|0.304|0.365|0.335|0.154|          |          |            |
|||||||||||||
|增(AEDA)|0.867|0.242|0.225|0.234|0.404|0.402|0.403|0.548|          |          |            |
|增(BERT)|0.850|0.242|0.225|0.234|0.407|0.406|0.406|0.503|          |          |            |
|增(MTV)|0.850|0.242|0.225|0.234|0.405|0.406|0.405|0.515|          |          |            |
|增(Double_Mix)|0.850|0.242|0.225|0.234|0.364|0.381|0.372|0.346|          |          |            |



### IMDB-Eval

- 方差规律：增+3L方差 **>** 基线模型方差

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- |
|增(AEDA)|0.850|0.429|0.437|0.433|0.279|0.277|0.278|
|增(AEDA)+VIC_Loss|0.517|0.429|0.437|0.433|0.627|0.627|0.627|
|增(BERT)|0.817|0.429|0.437|0.433|0.312|0.307|0.309|
|增(BERT)+VIC_Loss|0.567|0.429|0.437|0.433|0.626|0.628|0.627|
|增(MTV)|0.800|0.429|0.437|0.433|0.371|0.373|0.372|
|增(MTV)+VIC_Loss|0.517|0.429|0.437|0.433|0.543|0.549|0.546|
|增(Double_Mix)|0.700|0.432|0.438|0.435|0.446|0.452|0.449|


- 协方差：增+3L协方差和增协方差均＞基线模型

| 方法 | Acc  | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增(AEDA)|0.850|0.268|0.277|0.273|0.400|0.400|0.400|
|增(AEDA)+VIC_Loss|0.517|0.268|0.277|0.273|0.397|0.398|0.398|
|增(BERT)|0.817|0.268|0.277|0.273|0.386|0.390|0.390|
|增(BERT)+VIC_Loss|0.567|0.268|0.277|0.273|0.398|0.398|0.398|
|增(MTV)|0.800|0.268|0.277|0.273|0.375|0.381|0.378|
|增(MTV)+VIC_Loss|0.517|0.268|0.277|0.273|0.354|0.362|0.358|
|增(Double_Mix)|0.700|0.272|0.279|0.275|0.331|0.346|0.338|


### YELP-Eval

- 方差规律：增+3L方差 **>** 基线模型方差

| 方法 | Acc  | 原方A | 原方B | 均值 | 增方A | 增方B | 均值 |
| ---- | ---- | ----- | ----- | ---- | ----- | ----- | ---- |
|增(AEDA)|0.783|0.411|0.415|0.413|0.230|0.240|0.235|
|增(AEDA)+VIC_Loss|0.533|0.411|0.415|0.413|0.607|0.608|0.607|
|增(BERT)|0.800|0.411|0.415|0.413|0.284|0.269|0.277|
|增(BERT)+VIC_Loss|0.550|0.411|0.415|0.413|0.608|0.609|0.608|
|增(MTV)|0.750|0.411|0.415|0.413|0.263|0.257|0.260|
|增(MTV)+VIC_Loss|0.600|0.411|0.415|0.413|0.612|0.613|0.612|
|增(Double_Mix)|0.850|0.411|0.415|0.413|0.328|0.300|0.314|

- 协方差：增+3L协方差和增协方差均＞基线模型

| 方法 | Acc  | OCA  | OCB  | 均值 | ACA  | ACB  | 均值 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|增(AEDA)|0.783|0.256|0.260|0.258|0.405|0.404|0.405|
|增(AEDA)+VIC_Loss|0.533|0.256|0.260|0.258|0.388|0.389|0.388|
|增(BERT)|0.800|0.256|0.260|0.258|0.398|0.396|0.397|
|增(BERT)+VIC_Loss|0.550|0.256|0.260|0.258|0.388|0.389|0.389|
|增(MTV)|0.750|0.256|0.260|0.258|0.399|0.401|0.400|
|增(MTV)+VIC_Loss|0.600|0.256|0.260|0.258|0.390|0.391|0.391|
|增(Double_Mix)|0.850|0.256|0.260|0.258|0.350|0.375|0.362|

# 10.YELP,IMDB使用CL学习

- 增(BERT)+CL：每个Epoch，都会使用随机替换[Mask]，生成增强样本，而每个epoch的[Mask] ratio = △ * epoch

| 数据集 | 方法        | Acc       | △    |
| ------ | ----------- | --------- | ---- |
| YELP-1 | 增(BERT)    | 0.767     |      |
|        | 增(BERT)+CL | 0.750     | 0.03 |
|        | 增(BERT)+CL | 0.733     | 0.05 |
| YELP-2 | 增(BERT)    | 0.650     |      |
|        | 增(BERT)+CL | **0.700** | 0.03 |
|        | 增(BERT)+CL | 0.667     | 0.05 |
| YELP-3 | 增(BERT)    | 0.883     |      |
|        | 增(BERT)+CL | 0.867     | 0.03 |
|        |             |           |      |
| IMDB-1 | 增(BERT)    | 0.817     |      |
|        | 增(BERT)+CL | 0.783     | 0.03 |
| IMDB-2 | 增(BERT)    | 0.800     |      |
|        | 增(BERT)+CL | 0.750     | 0.03 |
| IMDB-3 | 增(BERT)    | 0.850     |      |
|        | 增(BERT)+CL | 0.833     | 0.03 |

- 随着[Mask] ratio的增大，增强样本特征与原始样本特征（求均值）的方差值

| Epoch | Ratio | Variance（YELP-1） | Variance（YELP-2） | Variance（YELP-3） |
| ----- | ----- | ------------------ | ------------------ | ------------------ |
| 1     | 0.05  | 4.163              | 3.783              | 3.750              |
| 2     | 0.10  | 4.183              | 3.808              | 3.754              |
| 3     | 0.15  | 4.195              | 3.798              | 3.764              |
| 4     | 0.20  | 4.229              | 3.834              | 3.799              |
| 5     | 0.25  | 4.275              | 3.822              | 3.824              |
| 6     | 0.30  | 4.258              | 3.842              | 3.847              |
| 7     | 0.35  | 4.214              | 3.821              | 3.844              |
| 8     | 0.40  | 4.234              | 3.795              | 3.820              |
| 9     | 0.45  | 4.216              | 3.834              | 3.891              |
| 10    | 0.50  | 4.273              | 3.846              | 3.852              |



| Epoch | Ratio | Variance（IMDB-1） | Variance（IMDB-2） | Variance（IMDB-3） |
| ----- | ----- | ------------------ | ------------------ | ------------------ |
| 1     | 0.05  | 3.502              | 3.523              | 3.381              |
| 2     | 0.10  | 3.502              | 3.539              | 3.387              |
| 3     | 0.15  | 3.502              | 3.540              | 3.401              |
| 4     | 0.20  | 3.530              | 3.514              | 3.398              |
| 5     | 0.25  | 3.519              | 3.528              | 3.382              |
| 6     | 0.30  | 3.507              | 3.529              | 3.402              |
| 7     | 0.35  | 3.514              | 3.523              | 3.373              |
| 8     | 0.40  | 3.534              | 3.529              | 3.394              |
| 9     | 0.45  | 3.504              | 3.524              | 3.392              |
| 10    | 0.50  | 3.528              | 3.520              | 3.392              |

# 11 探究方差

- 原原V：原始模型，对每条原始样本的特征求方差后的值，再求平均；增原V：增强模型，对每条原始样本的特征求方差后的值，再求平均
- 原增V：原始模型，对每条增强样本的特征求方差后的值，再求平均；增增V：增强模型，对每条增强样本的特征求方差后的值，再求平均
- 原原：原始模型，对所有原始样本的特征求方差；增原：增强模型，对所有原始样本的特征求方差
- 原增：原始模型，对所有增强样本的特征求方差；增增：增强模型，对所有增强样本的特征求方差

### YELP

| 方法 | Acc  | 原原V | 增原V | 原增V | 增增V | 原原 | 增原 | 原增 | 增增 |
| ---- | ---- | ----- | ----- | ----- | ----- | ---- | ---- | ---- | ---- |
|增(AEDA)|0.783|0.402|0.062|0.388|0.056|0.028|0.376|0.024|0.377|
|增(BERT)|0.800|0.402|0.127|0.398|0.126|0.028|0.317|0.027|0.317|
|增(MTV)|0.750|0.402|0.093|0.378|0.060|0.028|0.349|0.020|0.361|
|||||||||||
|增(AEDA)|0.633|0.164|0.033|0.172|0.031|0.260|0.377|0.251|0.376|
|增(BERT)|0.633|0.164|0.215|0.167|0.211|0.260|0.227|0.257|0.229|
|增(MTV)|0.650|0.164|0.192|0.203|0.129|0.260|0.234|0.187|0.252|
|||||||||||
|增(AEDA)|0.867|0.391|0.090|0.376|0.082|0.016|0.327|0.015|0.327|
|增(BERT)|0.850|0.391|0.059|0.387|0.058|0.016|0.383|0.016|0.383|
|增(MTV)|0.850|0.391|0.059|0.374|0.042|0.016|0.372|0.014|0.375|

## IMDB

| 方法 | Acc  | 原原V | 增原V | 原增V | 增增V | 原原 | 增原 | 原增 | 增增 |
| ---- | ---- | ----- | ----- | ----- | ----- | ---- | ---- | ---- | ---- |
|增(AEDA)|0.850|0.436|0.093|0.423|0.083|0.016|0.375|0.014|0.378|
|增(BERT)|0.817|0.436|0.190|0.433|0.189|0.016|0.261|0.016|0.262|
|增(MTV)|0.800|0.436|0.293|0.410|0.238|0.016|0.192|0.011|0.227|
|||||||||||
|增(AEDA)|0.767|0.085|0.359|0.097|0.348|0.338|0.126|0.149|0.129|
|增(BERT)|0.800|0.085|0.296|0.089|0.293|0.338|0.171|0.333|0.173|
|增(MTV)|0.733|0.085|0.179|0.079|0.136|0.338|0.288|0.015|0.310|
|||||||||||
|增(AEDA)|0.833|0.160|0.049|0.168|0.046|0.255|0.391|0.224|0.391|
|增(BERT)|0.833|0.160|0.234|0.164|0.234|0.255|0.215|0.248|0.215|
|增(MTV)|0.833|0.160|0.151|0.214|0.122|0.255|0.296|0.192|0.307|

# 13 使用动态调节参数，实现课程学习

**思路**：使用策略模型，策略模型自动生成参数$a$，控制增强样本中的[Mask]替换率（生成方差越来越大的样本），生成增强样本（例如生成十条增强样本）。使用Ot策略，寻找增强样本中最困难的增强样本，最后把增强样本和原始样本一并输入模型训练。

#### Q1：衡量样本难易程度的方法：

​	方差越大，增强样本越难

#### Q2：怎么做到训练的时候由简单到难的

​	通过动态控制参数$a$，生成方差越来越大的增强样本

#### 0 方法

​	方法由策略模型和目标模型组成，训练的过程中，策略模型生成动态变化的参数$a$，从而生成增强样本；把原始样本和增强样本输入目标模型训练，具体如下：

- 使用Bert-Base作为策略模型的基底：假设把一条原始样本输入Bert-base，将输出作平均池化后，输入策略模型的线性层（768,10），映射成（1, 10）的向量logits，取logits最大值中对应的索引，除以10，即$a$ = logits最大值中对应的索引 / 10 ，把$a$ 作为这条原始样本的替换[Mask]的比率，得到一条原始样本和一条增强样本，策略模型Loss = Loss1 + Loss2，各Loss说明如下：

  - 策略网络Loss_1 = 原始样本和增强样本在目标模型的分类Loss；

  - 策略模型Loss_2= $V_{1}$ / $V_{2}$，具体过程（**指导**策略模型生成方差越来越大的增强样本）：

    ①：先使用**策略模型**生成参数$a_{0}$，进而生成**当前Step**的增强样本$B_{1}$，并使用**目标模型**计算增强样本的方差$V_{1}$；

    ②：[更新目标模型参数]求出原始样本$B_{0}$和增强样本$B_{1}$在**目标模型**的分类损失，通过梯度下降一步更新**目标模型**的参数$w_{t}$；

    ③：使用策略模型重新生成一个参数$a_{1}$，进而生成**下一个Step**的增强样本$B_{2}$，使用参数更新后**目标模型**计算增强样本$B_{2}$的方差$V_{2}$；**如果**$V_{2}$ > $V_{1}$，说明策略模型更新的参数$a$方式是有效的。

- 目标模型：包含两个Loss，Loss1：把得到的原始样本和增强样本一并输入目标模型训练的分类Loss；**Loss2**：把增强样本中相同标签的样本作为正样本，不同标签的样本作为负样本，做一个对比学习


#### 0.新Loss实验结果

- 当前Step方差：当前Step增强样本的方差
- 下一个Step方差：下一个Step增强样本的方差

| Epoch | Acc  | Ratio | 当前Step方差 | 下一个Step方差 |
| ----- | ---- | ---- | ---- | ---- |
|0|0.550|0.434|0.041|0.099|
|1|0.600|0.416|0.139|0.176|
|2|0.800|0.413|0.310|0.337|
|3|0.850|0.462|0.410|0.429|
|4|0.667|0.391|0.455|0.446|
|5|**0.867**|0.436|0.448|0.458|
|6|0.817|0.400|0.464|0.464|
|7|0.783|0.414|0.453|0.463|
|8|0.867|0.465|0.456|0.468|
|9|0.867|0.424|0.466|0.469|


#### 1.实验结果

- **var-A**：方差策略网络中，使用BERT-**替换**[Mask]作为增强方法
- **var-B**：方差策略网络中，使用BERT-**插入**[Mask]作为增强方法
- **ot-A**：对每条原始样本 使用BERT-**替换**[Mask]增强方法 生成10条增强样本，使用ot筛选出1条最好的增强样本；并且每个Epoch的ratio增加0.03：epoch 0→1，ratio=0→0.03
- **纯增强-A**：只用一条样本作增强
- **var+ot**：方差策略网络+ot
- **insert,sub,swap,delete**: 使用var+ot方法，增强方法使用字符级别的增强

| 数据集     | var-A     | var-B | ot-A      | 纯增强-A | ot-B      | var+ot(-A) | var+ot(-B) | insert    | sub       | swap      | delete | 增(AEDA) | 增(BERT) | 增(MTV) | 增（Double Mix） |
| ---------- | --------- | ----- | --------- | -------- | --------- | ---------- | ---------- | --------- | --------- | --------- | ------ | -------- | -------- | ------- | ---------------- |
| YELP_1[80] | 0.883     | 0.833 | 0.850     | 0.833    | 0.867     | 0.850      | 0.883      | **0.900** | 0.883     | 0.883     | 0.850  | 0.783    | 0.800    | 0.750   | 0.850            |
| YELP_2     | 0.783     | 0.767 | 0.733     | 0.750    | 0.733     | 0.800      | 0.783      | 0.767     | 0.767     | 0.783     | 0.767  | 0.633    | 0.633    | 0.650   | **0.833**        |
| YELP_3     | **0.933** | 0.850 | 0.883     | 0.900    | 0.883     | **0.933**  | **0.933**  | 0.917     | 0.883     | **0.933** | 0.850  | 0.867    | 0.850    | 0.850   | 0.850            |
|            |           |       |           |          |           |            |            |           |           |           |        |          |          |         |                  |
| IMDB_1[80] | 0.767     | 0.783 | **0.883** | 0.783    | 0.850     | 0.800      | 0.850      | 0.850     | 0.800     | 0.800     | 0.817  | 0.850    | 0.817    | 0.800   | 0.850            |
| IMDB_2     | 0.817     | 0.833 | 0.833     | 0.850    | 0.833     | 0.833      | 0.850      | 0.800     | **0.867** | 0.783     | 0.850  | 0.767    | 0.800    | 0.733   | 0.800            |
| IMDB_3     | 0.833     | 0.817 | 0.833     | 0.817    | 0.817     | **0.850**  | 0.833      | 0.817     | 0.783     | 0.750     | 0.750  | 0.833    | 0.833    | 0.833   | 0.750            |
|            |           |       |           |          |           |            |            |           |           |           |        |          |          |         |                  |
| TREC[120]  | 0.783     | 0.917 | 0.883     | 0.767    | 0.850     | 0.850      | **0.933**  | 0.900     | 0.800     | 0.883     | 0.883  | 0.783    | 0.750    | 0.683   | 0.880            |
| SST-5[200] | 0.327     | 0.303 | 0.327     | 0.320    | **0.360** | 0.313      | **0.360**  | 0.347     | 0.307     | **0.360** | 0.293  | 0.333    | 0.327    | 0.353   | 0.302            |

#### 2.1 ot实验

说明：**只**使用ot，使用[MASK]替换增强方法，ratio = 0.03 * epoch；从十条增强样本中选出一条与原始样本最不相似的增强样本；随后增强样本与原始样本一并输入模型训练

| TREC | Epoch | Ratio | Var_Epoch | Result | SST5 | Epoch | Ratio | Var_Epoch | Result |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
||0|0.000|0.058|0.167||0|0.000|0.060|0.200|
||1|0.030|0.114|0.633||1|0.030|0.091|0.200|
||2|0.060|0.213|0.633||2|0.060|0.221|0.280|
||3|0.090|0.259|0.700||3|0.090|0.265|0.173|
||4|0.120|0.277|0.617||4|0.120|0.302|0.260|
||5|0.150|0.297|0.717||5|0.150|0.316|0.233|
||6|0.180|0.309|0.783||6|0.180|0.344|0.253|
||7|0.210|0.336|0.850||7|0.210|0.354|0.287|
||8|0.240|0.310|0.650||8|0.240|0.353|0.293|
||9|0.270|0.327|0.717||9|0.270|0.347|0.327|



| IMDB_1 | Epoch | Ratio | Var_Epoch | Result | YELP_1 | Epoch | Ratio | Var_Epoch | Result |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
||0|0.000|0.014|0.583||0|0.000|0.040|0.517|
||1|0.030|0.021|0.800||1|0.030|0.127|0.717|
||2|0.060|0.212|0.800||2|0.060|0.279|0.767|
||3|0.090|0.390|0.567||3|0.090|0.395|0.733|
||4|0.120|0.378|0.833||4|0.120|0.426|0.767|
||5|0.150|0.330|0.700||5|0.150|0.435|0.750|
||6|0.180|0.390|0.833||6|0.180|0.443|0.817|
||7|0.210|0.415|0.683||7|0.210|0.456|0.833|
||8|0.240|0.413|0.617||8|0.240|0.455|0.833|
||9|0.270|0.427|0.767||9|0.270|0.460|0.783|

#### 2.2 var+ot重复性实验

说明：使用策略网络自动生成ratio，使用插入[MASK]增强方法，对一条原始样本生成十条增强样本，并使用ot从十条增强样本中选出一条与原始样本最不相似的增强样本；随后该样本与原始样本一并输入模型训练

[**固定随机种子**]数据集：IMDB_1|| batch_size:6 ||增强方法: Insert

- Ratio：增强比率
- Var_Epoch：每个Epoch，所有增强样本的平均方差
- Var_Step1：当前Step的增强样本的平均方差
- Var_Step2：下一个Step的增强样本的平均方差

| Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|0|0.500|0.270|0.013|0.922|0.154|0|0.500|0.270|0.013|0.922|0.154|
|1|0.733|0.256|0.028|0.735|0.163|1|0.733|0.256|0.028|0.735|0.163|
|2|0.650|0.230|0.220|1.289|0.252|2|0.650|0.230|0.220|1.289|0.252|
|3|0.517|0.213|0.386|5.151|0.420|3|0.517|0.213|0.386|5.151|0.420|
|4|**0.700**|0.255|0.394|6.637|0.459|4|**0.700**|0.255|0.394|6.637|0.459|
|5|0.633|0.240|0.441|24.535|0.472|5|0.633|0.240|0.441|24.535|0.472|
|6|0.583|0.245|0.450|23.245|0.472|6|0.583|0.245|0.450|23.245|0.472|
|7|0.600|0.215|0.452|31.776|0.474|7|0.600|0.215|0.452|31.776|0.474|
|8|0.600|0.237|0.454|31.476|0.480|8|0.600|0.237|0.454|31.476|0.480|
|9|0.633|0.217|0.455|39.902|0.478|9|0.633|0.217|0.455|39.902|0.478|

[**不固定随机种子**]数据集：IMDB_1|| batch_size:6 ||增强方法: Insert

| Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|0|0.500|0.299|0.018|0.933|0.158|0|0.500|0.215|0.012|0.970|0.153|
|1|0.550|0.306|0.017|1.031|0.156|1|**0.600**|0.206|0.007|0.885|0.149|
|2|0.500|0.319|0.009|0.961|0.150|2|0.500|0.193|0.005|0.948|0.147|
|3|0.517|0.307|0.006|0.920|0.148|3|0.500|0.179|0.004|0.938|0.146|
|4|**0.533**|0.322|0.006|1.000|0.147|4|0.533|0.196|0.003|0.939|0.146|
|5|0.500|0.318|0.005|0.977|0.147|5|0.500|0.189|0.003|0.927|0.146|
|6|0.500|0.305|0.005|0.942|0.147|6|0.500|0.177|0.003|0.949|0.145|
|7|0.500|0.313|0.006|0.984|0.147|7|0.500|0.216|0.003|0.943|0.145|
|8|0.500|0.319|0.005|0.978|0.147|8|0.500|0.174|0.003|0.906|0.145|
|9|0.500|0.323|0.004|0.908|0.146|9|0.533|0.181|0.003|0.951|0.145|

[**固定随机种子**]数据集：**YELP_2**|| batch_size:6 ||增强方法: Insert

| Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|0|0.633|0.155|0.032|1.174|0.165|0|0.633|0.155|0.032|1.174|0.165|
|1|0.717|0.135|0.121|1.276|0.210|1|0.717|0.135|0.121|1.276|0.210|
|2|**0.900**|0.152|0.250|0.982|0.334|2|**0.900**|0.152|0.250|0.982|0.334|
|3|0.867|0.137|0.407|1.037|0.442|3|0.867|0.137|0.407|1.037|0.442|
|4|0.867|0.147|0.430|1.039|0.464|4|0.867|0.147|0.430|1.039|0.464|
|5|0.850|0.132|0.434|1.035|0.469|5|0.850|0.132|0.434|1.035|0.469|
|6|0.850|0.129|0.436|1.031|0.472|6|0.850|0.129|0.436|1.031|0.472|
|7|0.833|0.136|0.437|1.032|0.471|7|0.833|0.136|0.437|1.032|0.471|
|8|0.833|0.126|0.438|1.026|0.476|8|0.833|0.126|0.438|1.026|0.476|
|9|0.833|0.121|0.439|1.033|0.471|9|0.833|0.121|0.439|1.033|0.471|

[**不固定随机种子**]数据集：**YELP_2**|| batch_size:6 ||增强方法: Insert

| Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|0|**0.517**|0.326|0.016|0.939|0.156|0|**0.533**|0.225|0.021|0.959|0.161|
|1|0.500|0.287|0.012|1.072|0.152|1|0.517|0.225|0.038|0.961|0.170|
|2|0.500|0.302|0.023|1.278|0.159|2|0.483|0.221|0.054|0.924|0.186|
|3|0.500|0.338|0.030|1.184|0.165|3|0.500|0.237|0.053|1.058|0.182|
|4|0.500|0.293|0.021|1.206|0.160|4|0.500|0.223|0.023|0.980|0.163|
|5|0.500|0.298|0.019|1.014|0.160|5|0.500|0.226|0.019|1.040|0.158|
|6|0.500|0.346|0.013|1.180|0.154|6|0.500|0.229|0.010|1.007|0.151|
|7|0.500|0.288|0.005|0.956|0.148|7|0.500|0.244|0.007|0.990|0.149|
|8|0.500|0.353|0.001|0.914|0.145|8|0.500|0.263|0.007|0.909|0.148|
|9|0.500|0.285|0.001|0.540|0.145|9|0.483|0.239|0.007|1.037|0.148|


[**固定随机种子**]数据集：Trec|| batch_size:6 ||增强方法: insert

| Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Step1/Step2 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|0|0.400|0.268|0.060|1.046|0.105|0|0.400|0.268|0.060|1.046|0.105|
|1|0.517|0.283|0.145|1.182|0.180|1|0.517|0.283|0.145|1.182|0.180|
|2|0.633|0.298|0.300|3.016|0.294|2|0.633|0.298|0.300|3.016|0.294|
|3|0.633|0.284|0.336|4.146|0.333|3|0.633|0.284|0.336|4.146|0.333|
|4|0.650|0.296|0.354|4.976|0.343|4|0.650|0.296|0.354|4.976|0.343|
|5|0.800|0.306|0.354|2.668|0.346|5|0.800|0.306|0.354|2.668|0.346|
|6|0.850|0.289|0.361|4.649|0.355|6|0.850|0.289|0.361|4.649|0.355|
|7|0.817|0.265|0.355|8.465|0.358|7|0.817|0.265|0.355|8.465|0.358|
|8|0.850|0.286|0.362|8.119|0.359|8|0.850|0.286|0.362|8.119|0.359|
|9|0.833|0.269|0.362|7.431|0.366|9|0.833|0.269|0.362|7.431|0.366|

[**不固定随机种子**]数据集：Trec|| batch_size:6 ||增强方法: insert

| Epoch | Acc | Ratio | Var_Epoch | Var_Step1 | Var_Step2 | Epoch | Acc | Ratio | Var_Epoch | Var_Step1 | Var_Step2 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |

#### 3.方差

​	原原：原始模型，对所有原始样本的特征求方差；增原：增强模型，对所有原始样本的特征求方差

- YELP

| 方法     | Acc       | 原原  | 增原      | Acc       | 原原  | 增原      | Acc       | 原原  | 增原      |
| -------- | --------- | ----- | --------- | --------- | ----- | --------- | --------- | ----- | --------- |
| 增(AEDA) | 0.783     | 0.028 | 0.376     | 0.633     | 0.260 | 0.377     | 0.867     | 0.016 | 0.327     |
| 增(BERT) | 0.800     | 0.028 | 0.317     | 0.633     | 0.260 | 0.227     | 0.850     | 0.016 | **0.383** |
| 增(MTV)  | 0.750     | 0.028 | 0.349     | 0.650     | 0.260 | 0.234     | 0.850     | 0.016 | 0.372     |
| **ours** | **0.883** | 0.028 | **0.402** | **0.783** | 0.260 | **0.409** | **0.933** | 0.016 | 0.382     |

- IMDB

| 方法     | Acc       | 原原  | 增原      | Acc       | 原原  | 增原      | Acc   | 原原  | 增原      |
| -------- | --------- | ----- | --------- | --------- | ----- | --------- | ----- | ----- | --------- |
| 增(AEDA) | **0.850** | 0.016 | 0.375     | 0.767     | 0.338 | 0.126     | 0.833 | 0.255 | 0.288     |
| 增(BERT) | 0.817     | 0.016 | 0.261     | 0.800     | 0.338 | 0.126     | 0.833 | 0.255 | 0.215     |
| 增(MTV)  | 0.800     | 0.016 | 0.192     | 0.733     | 0.338 | **0.288** | 0.833 | 0.255 | 0.296     |
| **ours** | 0.767     | 0.016 | **0.413** | **0.817** | 0.338 | 0.262     | 0.833 | 0.255 | **0.417** |

#### 4.YELP三个小数据集(80条)训练时的实验结果

- Acc：模型的分类准确度
- Ratio：模型自动生成的BERT-替换[Mask]的比率
- Variance：生成增强样本的样本级方差

| Epoch | Acc | Ratio | Variance | Acc | Ratio | Variance | Acc | Ratio | Variance |
| ----- | ------ | ---------------- | ------------------- | ---- | ---------------- | ------------------- | ------------------- | ------------------- | ------------------- |
|0|0.717|0.159|0.027|0.500|0.100|0.030|0.617|0.158|0.038|
|1|0.717|0.175|0.240|0.683|0.100|0.046|0.650|0.155|0.151|
|2|**0.883**|**0.165**|**0.323**|0.667|0.106|0.199|**0.933**|**0.151**|**0.266**|
|3|0.783|0.169|0.455|0.600|0.104|0.323|0.883|0.155|0.380|
|4|0.850|0.165|0.461|**0.783**|**0.110**|**0.377**|0.850|0.155|0.400|
|5|0.817|0.165|0.433|0.583|0.104|0.395|0.700|0.155|0.392|
|6|0.767|0.175|0.468|0.667|0.104|0.390|0.650|0.168|0.394|
|7|0.783|0.175|0.464|0.733|0.100|0.361|0.600|0.159|0.376|
|8|0.800|0.171|0.445|0.667|0.104|0.374|0.800|0.155|0.392|
|9|0.867|0.165|0.483|0.700|0.104|0.392|0.850|0.155|0.393|

#### 5.IMDB三个小数据集(80条)训练时的实验结果

| Epoch | Acc       | Ratio     | Variance  | Acc       | Ratio     | Variance  | Acc       | Ratio     | Variance  |
| ----- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- |
|0|0.500|0.335|0.017|0.500|0.314|0.022|0.500|0.294|0.018|
|1|**0.767**|**0.325**|**0.039**|**0.817**|**0.308**|**0.066**|0.500|0.290|0.009|
|2|0.550|0.329|0.295|0.783|0.306|0.253|0.683|0.294|0.063|
|3|0.550|0.325|0.440|0.733|0.302|0.381|0.683|0.288|0.230|
|4|0.583|0.328|0.449|0.717|0.312|0.406|0.600|0.294|0.372|
|5|0.733|0.325|0.450|0.783|0.302|0.409|0.800|0.294|0.303|
|6|0.583|0.325|0.258|0.767|0.310|0.412|0.700|0.288|0.308|
|7|0.733|0.325|0.453|0.733|0.307|0.471|0.817|0.290|0.313|
|8|0.700|0.329|0.465|0.633|0.312|0.385|**0.833**|**0.288**|**0.314**|
|9|0.700|0.328|0.466|0.733|0.315|0.390|0.833|0.300|0.330|

# 13 增强方法数据集统计
说明：

- [全]代表在全数据集上训练
- [S5]代表在每个分类取5个样本作训练集
- B：使用Bert-base；RB：使用Roberta-base；RL：使用Roberta-large作模型

|      | 方法                                                         | M      | IMDB              | TREC-c            | TREC-f    | SST-5             | SST-2      | HUFF      | FEWREL    | COV_C    | AMZN     | MR       | CR       | SUBJ     | CoLA     | MPQA     | YELP-2    | WOS             | NYT             | RCV1_V2          | SNIPS     | YELP-5     | AG_N      | News20            | Review50          | CLINC150          | ATIS       | Bank77     | T-Bot      | ARC                | QC_Science         | EURLEX57K     | 序   | Eval_Information                                   |
| ---- | ------------------------------------------------------------ | ------ | ----------------- | ----------------- | --------- | ----------------- | ---------- | --------- | --------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | --------- | --------------- | --------------- | ---------------- | --------- | ---------- | --------- | ----------------- | ----------------- | ----------------- | ---------- | ---------- | ---------- | ------------------ | ------------------ | ------------- | ---- | -------------------------------------------------- |
|      | 分类数                                                       |        | 2                 | 6                 | 50        | 5                 | 2          | 41        | 64        | 87       | 318      | 2        | 2        | 2        | 2        | 2        | 2         | 141             | 166             | 103              |           | 5          |           | 20                | 50                | 150               | 17         | 77         | 87         |                    |                    |               |      |                                                    |
|      | 指标说明                                                     |        |                   |                   |           |                   |            | Top1_Acc  | Top1_Acc  | Top1_Acc | Top1_Acc |          |          |          |          |          |           | Macro/Micro     | Macro/Micro     | Macro/Micro      |           |            |           |                   |                   |                   |            |            |            | R@1/@5/@5          | R@1/@5/@5          | RP@5/nDCG@5   |      |                                                    |
| 0    | 21AEDA[[Paper](https://arxiv.org/pdf/2108.13230v1.pdf)]      | B      |                   | 97.20[全]         |           |                   | 91.76[全]  |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 0    |                                                    |
| 1    | 21TAA[[Paper](https://arxiv.org/pdf/2109.00523.pdf)]         | B      | 75.68[80]         | 81.47[120]        |           | 40.28[200]        |            |           |           |          |          |          |          |          |          |          | 81.75[80] |                 |                 |                  |           | 45.29[200] |           |                   |                   |                   |            |            |            |                    |                    |               | 1    | IMDB[60]/SST5[150]/TREC[60]/YELP_2[60]/YELP_5[150] |
| 2    | 21MTV[[Paper](https://arxiv.org/pdf/2103.07552.pdf)]         | B      |                   | 86.4[全]          |           |                   | 87[全]     |           |           |          |          |          |          | 95.6[全] |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 2    |                                                    |
| 3    | 21Triplet+CL[[Paper](https://arxiv.org/pdf/2103.07552.pdf)]  | B      |                   |                   |           |                   |            | 23.8[S10] | 47.1[S10] | 48.9[S3] | 18.9[S3] |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 3    | 不详                                               |
| 4    | 22DND[[Paper](https://openreview.net/pdf?id=Ucx3DQbC9GH)]    | **RB** | 69.6[S5]/95.7[全] | 74.1[S5]/98.0[全] |           | 29.7[S5]/58.3[全] |            |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           | 50.4[S5]/85.2[全] | 49.8[S5]/74.9[全] | 88.4[S5]/96.6[全] |            |            |            |                    |                    |               | 4    | [S5]不详                                           |
| 5    | 22Text_Smooth[[Paper](https://arxiv.org/pdf/2202.13840.pdf)] | B      |                   | 67.51[60]         |           |                   | 59.37[20]  |           |           |          |          |          |          |          |          |          |           |                 |                 |                  | 88.85[70] |            |           |                   |                   |                   |            |            |            |                    |                    |               | 5    | SST2[20]/SNIPS[70]/TREC[60]                        |
| 6    | 22Tree_Mix[[Paper](https://aclanthology.org/2022.naacl-main.385.pdf)] | B      | 94.34[全]         | 97.95[全]         | 93.20[全] |                   | 93.92[全]  |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            | 94.72[全] |                   |                   |                   |            |            |            |                    |                    |               | 6    |                                                    |
| 7    | 22CIAug[[Paper](https://aclanthology.org/2022.naacl-main.127.pdf)] | B      |                   | 98.20[全]         | 92.80[全] |                   | 92.93[10K] |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 7    |                                                    |
| 8    | 22Double_Mix[[Paper](https://arxiv.org/pdf/2209.05297.pdf)]  | B      | 84.14[全]         | 97.40[全]         |           |                   | 92.21[全]  |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 8    |                                                    |
| 9    | 23TAU[[Paper](https://aclanthology.org/2023.findings-acl.466.pdf)] | B      |                   | 0.641[S5]         |           |                   |            |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   | 0.906[S5]  | 0.733[S5]  | 0.71[S5]   |                    |                    |               | 9    | 不详                                               |
|      | 23TAU                                                        | B      |                   | 0.773[S10]        |           |                   |            |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   | 0.933[S10] | 0.839[S10] | 0.788[S10] |                    |                    |               |      | 不详                                               |
| 10   | 23CEAA[[Paper](https://aclanthology.org/2023.findings-acl.137.pdf)] | B      |                   |                   |           |                   |            |           |           |          |          |          |          |          |          |          |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            | 0.50/0.72/0.80[全] | 0.68/0.86/0.90[全] | 0.76/0.78[全] | 10   |                                                    |
| 11   | 23PROMPTDA[[Paper](https://arxiv.org/pdf/2205.09229.pdf)]    | **RL** |                   |                   |           | 43.3[S8]          | 89.5[S8]   |           |           |          |          | 83.7[S8] | 88.3[S8] | 86.8[S8] | 55.9[S8] | 78.4[S8] |           |                 |                 |                  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 11   | 在full size test sets上评估                        |
| 12   | 23method[[Paper](https://aclanthology.org/2023.findings-acl.489.pdf)] | B      |                   |                   |           |                   |            |           |           |          |          |          |          |          |          |          |           | 81.26/86.77[全] | 66.85/78.34[全] | 67.41//86.06[全] |           |            |           |                   |                   |                   |            |            |            |                    |                    |               | 12   |                                                    |
|      | 23method                                                     | **RB** |                   |                   |           |                   |            |           |           |          |          |          |          |          |          |          |           | 81.31/86.96[全] | 68.16/79.64[全] | 68.50/86.84[全]  |           |            |           |                   |                   |                   |            |            |            |                    |                    |               |      |                                                    |
